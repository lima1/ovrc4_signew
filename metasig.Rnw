\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]{hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{booktabs}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
# this is equivalent to \SweaveOpts{...}
opts_chunk$set(fig.path='figure/metasig-', fig.align='center',
fig.show='hold',warning=FALSE, echo=FALSE)
options(replace.assign=TRUE,width=90)
@

\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}

\title{Risk Prediction for Late-stage Ovarian Cancer Using the Corpus of
Published Expression Data - Supplemental Figures}

\author{Markus Riester, Levi Waldron, Aedin Culhane, Curtis \\
Huttenhower, Franziska Michor, Giovanni Parmigiani, Michael Birrer}
\maketitle

Code to reproduce all results presented in this paper is
available at \url{https://bitbucket.org/lima1/ovrc4_signew}.

<<load, include=FALSE>>=
library(genefilter)
library(survival)
library(annotate)
library(hgu133a.db)
library(metafor)
library(ggplot2)
library(xtable)
library(survIDINRI)
library(ROCR)
library(RColorBrewer)
library(lattice)
library(maxstat)
library(exactRankTests)
library(pROC)

# only to print the version number in the Appendix. We load the data generated
# with the createEsetsList script
library(curatedOvarianData)

source("src/metaCMA.R")
source("src/utils.R")
@
<<createesets, cache=TRUE>>=
load("input/eset.scaled.rda")
esets    <- esets[-match("GSE19829.GPL8300_eset",names(esets))]
esets.f  <- metaCMA.common.gene.esets(esets)
@

<<addsurvobj, results='hide'>>=
esets.uf <- esets
japan.idx <- match("GSE32062.GPL6480_eset",names(esets.f))
esets.f <- esets.f[-japan.idx]
@

<<optimizecoefs, cache=TRUE>>=
coefs = metaCMA.coefs(esets.f)
@

<<optimizegrid, cache=TRUE,results='hide'>>=
ma = lapply(c(5,10,seq(25,250,25)), function(i)
    #metaCMA(esets.f,coefs=coefs,n=i,method="penalizedSurv",fold=5))
    metaCMA(esets.f,coefs=coefs,n=i))
@

\clearpage
\normalsize

\begin{figure}
<<validate, cache=TRUE>>=
.plotN <- function(esets, ma) {
    w <- sapply(esets,ncol)
    cidx = lapply(ma, function(x) sapply(1:length(esets), function(i)
        evaluate(x$fits[[i]]$risk, measure=new("UnoC"),
        newy=esets[[i]]$y,add=list(tau=365.25*4) )))

    dfCV <- stack(as.data.frame(do.call(rbind,cidx)))
    dfCV <- cbind(dfCV, Genes=c(5,10,seq(25,250,25)))
    dfCV$ind <- unlist(lapply(.getDatasetNames(esets), rep, 12))
    ggplot(dfCV, aes(values, Genes))+geom_point()+facet_wrap(~ind) +
    ylab("Number of Genes")+xlab("C-Index (Concordance)")
}
.plotN(esets.f,ma)
@
\caption{In the \textit{leave-one-dataset-out} cross-validation in
\textbf{Figure 1-2}
of the main paper, we used a fixed gene signature size of 200 genes.  Here we
show the influence of this cutoff on the prediction concordance. Each point
represents the prediction concordance of a model with $y$ genes in the
corresponding dataset that was trained using the remaining datasets only.}
\label{fig:cutoff:train}
\end{figure}

<<finalmodel,cache=TRUE>>=
tmp <- metaCMA.opt(esets.f,coef=coefs,n=200)
final.model <- tmp$model
@

<<loadvaldata,cache=TRUE>>=
load("input/eset.binary.scaled.rda")
esets.binary <- esets
load("input/eset.validation.scaled.rda")
esets.validation <- esets
load("input/eset.allos.scaled.rda")
esets.allos <- esets
load("input/eset.debulking.scaled.rda")
esets.debulking <- esets
@


<<tablemodel>>=
sig <- names(final.model@coefficients)
esets.f.all <- esets.f
esets.f.all$GSE32062.GPL6480_eset <- esets.validation$GSE32062.GPL6480_eset

probesets <- do.call(cbind, lapply(esets.f.all, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

write.csv(data.frame(Genes=sig, probesets, "Pooled Cox Coefficient"=
 final.model@coefficients,
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig))
), file="final_signature.csv",
row.names=FALSE)
@

\begin{figure}
<<ngeneshm>>=
genes <- lapply(ma[[10]]$fits, function(x) names(x$fit@coefficients))
names(genes) <- .getDatasetNames(esets.f)

genes[["Final Model"]] <- names(final.model@coefficients)
gmt.lodocv <- new("gsagenesets", genesets=genes, geneset.names=names(genes))
plot(gmt.lodocv,main="Overlap of Signatures",cex=0.8)
@
\caption{
In the cross-validation, 8 different models were trained (one for every
validation data set), and this plot shows how similar the models are. This
plot visualizes the overlap of the gene signatures. The more isolated a data
sets is, the higher the influence on the final gene signature. So excluding
TCGA or Bonome, for example, will change the signature
significantly. GSE18520 and PMID17290060 were not used for training because
both comprise less than 75 samples and are thus tested with the final model.
}
\label{fig:signature:overlap}
\end{figure}

<<optimizesize, cache=TRUE,results='hide'>>=
sizes <- sort(sapply(esets.f, ncol),decreasing=TRUE)
ma.sizes <- lapply(1:length(sizes), function(i) metaCMA(esets.f,coefs=coefs,
n=200, filter.fun= function(eset) ncol(eset) < sizes[i] ))
@

<<optimizesizerev, cache=TRUE, results='hide'>>=
sizes.rev <- sort(sapply(esets.f, ncol))
ma.sizes.rev <- lapply(1:length(sizes), function(i) metaCMA(esets.f,coefs=coefs,
n=200, filter.fun= function(eset) ncol(eset) > sizes.rev[i] ))
@

<<loadmodeltcga, cache=TRUE,results='hide'>>=
load("input/TCGA11-ovsig.RData")
model.tcga <- model.official
data(TCGA_eset, package="curatedOvarianData")
TCGA.validation.eset <- TCGA_eset[ ,TCGA_eset$batch %in% c("17", "18", "19", "21", "22", "24")]
featureNames(TCGA.validation.eset) <- sub("-", "hyphen", featureNames(TCGA.validation.eset))
TCGA.validation.eset <- TCGA.validation.eset[ ,!is.na(TCGA.validation.eset$days_to_death) &
                                             !is.na(TCGA.validation.eset$vital_status)]
TCGA.validation.eset$y <- Surv(TCGA.validation.eset$days_to_death / 30,
                               TCGA.validation.eset$vital_status == "deceased")
##Validation set 2:
data(GSE9891_eset, package="curatedOvarianData")
featureNames(GSE9891_eset) <- sub("-", "hyphen", featureNames(GSE9891_eset))
GSE9891_eset <- GSE9891_eset[ ,!is.na(GSE9891_eset$days_to_death) &
                             !is.na(GSE9891_eset$vital_status)]
GSE9891_eset$y <- Surv(GSE9891_eset$days_to_death / 30, GSE9891_eset$vital_status == "deceased")

#Validation set 3, Bonome et al. (2008):
data(GSE26712_eset, package="curatedOvarianData")
featureNames(GSE26712_eset) <- sub("-", "hyphen", featureNames(GSE26712_eset))
GSE26712_eset <- GSE26712_eset[ ,!is.na(GSE26712_eset$days_to_death) &
                               !is.na(GSE26712_eset$vital_status)]
GSE26712_eset$y <- Surv(GSE26712_eset$days_to_death / 30,
                        GSE26712_eset$vital_status == "deceased")
data(PMID17290060_eset, package="curatedOvarianData")
featureNames(PMID17290060_eset) <- sub("-", "hyphen", featureNames(PMID17290060_eset))
PMID17290060_eset <- PMID17290060_eset[ ,!is.na(PMID17290060_eset$days_to_death) &
                                       !is.na(PMID17290060_eset$vital_status)]
PMID17290060_eset$y <- Surv(PMID17290060_eset$days_to_death / 30,
                            PMID17290060_eset$vital_status == "deceased")
@


<<prepareclinicaldf, cache=TRUE>>=
X <- esets.uf[-japan.idx]
risk <- lapply(X, function(X) predict(model.tcga, newdata=X,
 type="lp")@lp)
for (i in 1:length(X)) X[[i]]$risk <- risk[[i]]
for (i in 1:length(X)) 
    X[[i]]$risk2 = ma[[10]]$fits[[i]]$risk@lp
X <- X[-grep("TCGA",names(X))]
dfrc <- .createClinical(X)
dfrc$risk_tcga <- unlist(sapply(X, function(x) x$risk))
dfrc$risk <- unlist(sapply(X, function(x) x$risk2))  
idx.stagedeb <- !is.na(dfrc$age) & !is.na(dfrc$debulking)
idx.stagedeb <- !is.na(dfrc$tumorstage) & !is.na(dfrc$debulking)
dfrc$debulking_orig <- dfrc$debulking
dfrc$debulking <- as.numeric(dfrc$debulking)
@

\begin{figure}
<<reclassificationclinical,cache=TRUE,fig.width=12,fig.height=3,out.width="0.9\\textwidth",out.height="0.3\\textwidth",results='hide'>>=
par(mfrow=c(1,3))
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*1, 
title="All Training Datasets")
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*3, 
title="All Training Datasets")
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*5, 
title="All Training Datasets")
@
\caption{The additional value of our gene signature compared to age and
debulking status alone. 
These plots visualize the
Integrated Discrimination Improvement (IDI, \cite{Pencina:2008,Uno:2012}), a
measure of discrimination of two competing nested survival models. Shown are
plots for events within the first 1, 3 and 5 years, respectively. The y-axis
shows the probability that the differences in predicted risk between the new
and old models are smaller than $s$, $P(D \leq s)$. The bold curve shows this
probability for patients who suffered from an event within the specified time,
the thin line for those who did not. The new model is better when patients
with events have a higher estimated risk (low probability that the risk
difference is smaller than $s$) and those without event a lower risk (high
probability that risk difference is smaller than $s$). The y-axis shows the
discrimination improvement by varying $s$, with the grey dots representing the
IDI. See also \cite{Uno:2012} for a more detailed explanation of these plots.
Our gene signature improved for all three
tested time points a model using only debulking status and age.} 
\label{fig:reclass}
\end{figure}

\begin{figure}
<<plotmodeltcgavalidation, results='hide'>>=
par(mfrow=c(2,2))

plot(model.tcga,newdata=TCGA.validation.eset,newy=TCGA.validation.eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="Overall Survival (%)",main="TCGA test set")

plot(model.tcga,newdata=GSE9891_eset,newy=GSE9891_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="",main="Tothill")
            
plot(model.tcga,newdata=GSE26712_eset,newy=GSE26712_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="Overall Survival (%)",main="Bonome")

plot(model.tcga,newdata=PMID17290060_eset,newy=PMID17290060_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="",main="Dressman")
@
\caption{TCGA model applied to the author test sets shown in Figure 2c of the TCGA paper
\cite{TCGA:2011}. The identical results show that our implementation of the
TCGA model is correct. Red survival curves correspond to high risk patients,
blue curves to low risk patients.}
\end{figure}

\begin{figure}
<<reclassification,cache=TRUE,fig.width=12,fig.height=3,out.width="0.9\\textwidth",out.height="0.3\\textwidth",results='hide'>>=
par(mfrow=c(1,3))
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25, 
title="All Training Datasets")
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25*3, 
title="All Training Datasets")
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25*5, 
title="All Training Datasets")
@
\caption{Comparison of all \textit{leave-one-dataset-out} cross-validated risk scores
and the risk scores calculated by the TCGA model.  
See \textbf{Supplemental Figure~\ref{fig:reclass}} and \cite{Uno:2012} for an explanation of these plots.  
Shown are again plots for events within the first
1, 3 and 5 years, respectively. 
Our model shows a small but consistent reclassification improvement over all
three time points.}
\label{fig:reclass:tcga}
\end{figure}

\begin{figure}
<<subtypes, results='hide'>>=
subtypes <- read.delim("input/TCGA_489_UE.k4.txt")

esets.f$TCGA_eset$subtype <-
subtypes[match(make.names(substr(esets.f$TCGA_eset$alt_sample_name,1,20)),
subtypes[,1]),2]
 esets.f$TCGA_eset$risk <- predict(final.model, newdata=esets.f$TCGA_eset)@lp
 esets.f$TCGA_eset$risk_unbiased <- ma[[10]]$fits$TCGA_eset$risk@lp

 esets.tcga.subtypes <- lapply(levels(esets.f$TCGA_eset$subtype),function(s)
 esets.f$TCGA_eset[,!is.na(esets.f$TCGA_eset$subtype) &
 esets.f$TCGA_eset$subtype==s])
 names(esets.tcga.subtypes) <- levels(esets.f$TCGA_eset$subtype)
metaCMA.forest.label(esets.tcga.subtypes, label="risk_unbiased")
@
\caption{C-Index of a model trained in all training datasets except TCGA and
then validated on the 4 subtypes separately.}
\end{figure}

\begin{figure}
<<elmeta,fig.width=7,fig.height=4.7,out.width="0.9\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
Xs.all <- lapply(esets.f, .dichotomizeshortlong, l=365.25, label="os_1yr")
preds <- lapply(1:length(Xs.all), function(i) predict(ma[[10]]$fits[[i]]$fit,
newdata=Xs.all[[i]])@lp)

labels <- lapply(Xs.all, function(X) X$os_1yr)
titles <- .getDatasetNames(Xs.all)
idx <- c(1,2,5,6,8)
preds.logit.age <- .p2logitMV(Xs.all[idx], preds=preds[idx],
 fits=ma[[10]]$fits[idx],y="os_1yr",x1="age_at_initial_pathologic_diagnosis")

aucs <- .plotROCpanel(preds.logit.age,labels[idx],titles[idx],2,3)
@
\caption{Prediction of events within the first year in a
\textit{leave-one-dataset-out}
cross-validation. The prediction model calculates for each sample a score. The
higher the score, the higher the probability the patient will die within the
first year. For each dataset, the model is trained using only the remaining
datasets. The model utilizes the overall survival gene signature
(\textbf{Supplemental Table 1}) and the age of the patients. ROC curves visualize the
true and false positive rates as a function of the probability cutoffs.}  
\end{figure}



<<concdeltaclinical1, cache=TRUE>>=
res.dfrc <- Inf.Cval.Delta(cbind(as.numeric(dfrc$days_to_death[idx.stagedeb]),
dfrc$vital_status[idx.stagedeb]=="deceased"),
cbind(dfrc$tumorstage[idx.stagedeb], dfrc$debulking[idx.stagedeb] ), 
cbind(dfrc$tumorstage[idx.stagedeb],
dfrc$debulking[idx.stagedeb], dfrc$risk[idx.stagedeb]),tau=365.25*4)
@
<<concdeltaclinical2, cache=TRUE>>=
res.dfrc2 <- Inf.Cval.Delta(cbind(as.numeric(dfrc$days_to_death[idx.stagedeb]),
dfrc$vital_status[idx.stagedeb]=="deceased"),
dfrc$risk[idx.stagedeb],
cbind(dfrc$tumorstage[idx.stagedeb],
dfrc$debulking[idx.stagedeb], dfrc$risk[idx.stagedeb]),tau=365.25*4)
@

<<addearlystage>>=
ids <- esets.allos$TCGA_eset$summarystage=="early" &
    esets.allos$TCGA_eset$summarygrade!="low"
esets.validation <- c(esets.validation, TCGA_eset=esets.allos$TCGA_eset[, ids])
@
<<clinicalvalidation, cache=TRUE>>=
X <- esets.validation
dfrcval <- .createClinical(esets.validation)
for (i in 1:length(X)) X[[i]]$risk <- predict(final.model, newdata=X[[i]], type="lp")@lp
dfrcval$risk <- unlist(sapply(X, function(x) x$risk))
for (i in 1:length(X)) X[[i]]$risk <- predict(model.tcga, newdata=X[[i]], type="lp")@lp
dfrcval$risk_tcga <- unlist(sapply(X, function(x) x$risk))
@

<<debulkingmetaprepare>>=
Xs <- esets.debulking 
Xs.all <- metaCMA.common.gene.esets(Xs)
for (i in 1:length(Xs.all)) Xs.all[[i]]$debulking <- as.factor(Xs.all[[i]]$debulking)
Xs.alls3 <- lapply(Xs.all, function(X) X[,X$tumorstage==3 |
is.na(X$tumorstage)])
@

<<debulkingmetas3, cache=TRUE, results='hide'>>=
# use only stage 3 patients for training, as stage 4 patients typically don't
# get debulking surgery
coefs.debulking.s3 <- metaCMA.coefs(Xs.alls3, y="debulking", family=binomial)
res.debulking.s3  <- metaCMA(Xs.alls3,y="debulking",coefs=coefs.debulking.s3, n=200,
filter.fun=.debulkingFilter)
@


\begin{figure}
<<debulkingmetaplot, cache=TRUE>>=
preds <- lapply(res.debulking.s3$fits,function(fit) fit$risk@lp)
labels <- lapply(Xs.alls3, function(X) X$debulking)
titles <- .getDatasetNames(Xs.alls3)
idx <- !sapply(Xs.alls3,.debulkingFilter)
preds.logit <- .p2logit(Xs.alls3[idx], fits=res.debulking.s3$fits[idx])
aucs.db <- .plotROCpanel(preds.logit,labels[idx],titles[idx],3,3)
@
\caption{Prediction of suboptimally debulked tumors in a leave-one-dataset-out
cross-validation. The prediction model calculates for each sample a score. The
higher the score, the higher the probability the tumor will be not optimally
debulkable. For each dataset, the model is trained using only the remaining
datasets. The model utilizes gene expression only (\textbf{Supplemental Table 2}). ROC
curves visualize the true and false positive rates as a function of the
probability cutoffs.}  
\label{fig:roc:debulking}
\end{figure}

<<finalmodeldebulking,cache=TRUE>>=

tmp <- metaCMA.opt(Xs.alls3, coefs=coefs.debulking.s3,n=200,y="debulking")
final.model.debulking <- tmp$model
sig <- names(final.model.debulking@coefficients)

probesets <- do.call(cbind, lapply(Xs.all, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

write.csv(data.frame(Genes=sig, probesets, 
"Pooled LogIt Coefficient"=
final.model.debulking@coefficients,
"Mean Optimal"= apply(tmp$train$X[which(tmp$train$y=="optimal"),],2,mean),
"Mean Suboptimal"= apply(tmp$train$X[which(tmp$train$y=="suboptimal"),],2,mean),
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig))),
 file="final_signature_debulking.csv",row.names=FALSE)
@

\clearpage
\bibliographystyle{plain}
\bibliography{metasig}
\newpage
\clearpage
\appendix
\section{Main Figures}
This supplement was generated with the knitr R package and contains the
complete analysis of this study. The source code is available at
\url{https://bitbucket.org/lima1/ovrc4_signew} to ease the reproducibility of
the study.  The following section generates the figures of the main paper.
\renewcommand{\thefigure}{\arabic{figure}}
\setcounter{figure}{0}

\begin{figure}
<<kmplotstrain,results='hide'>>=
best.idx <- rep(10, length(esets.f))
X <- esets.f

for (i in 1:length(X)) { 
    X[[i]]$risk = ma[[best.idx[i]]]$fits[[i]]$risk@lp
}
res.lodo <- .lodocvPlot(X)
for (i in 1:length(X)) { 
    X[[i]]$risk <- predict(model.tcga, newdata=X[[i]])@lp
}
res.lodo.tcga <- .lodocvPlot(X, plot=FALSE)
@
\caption{\textit{Leave-one-dataset-out} cross-validation of a novel gene signature for
predicting overall survival in late stage ovarian cancer.
See caption in the main paper for details.}
\end{figure}

\begin{figure}
<<validationexternal,cache=TRUE,fig.width=7,fig.height=4.7,out.width="0.9\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
res.val <- .valPlot(final.model)
res.val.tcga <- .valPlot(model.tcga, plot=FALSE)
@
\caption{Validation of the final signature in independent data. 
See caption in the main paper for details.}
\end{figure}

\begin{figure}
\subfigure[]{
<<comptcga,fig.width=7,fig.height=7,out.width="0.6\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
dfrcval$debulking_orig <- dfrcval$debulking
dfrcboth <- rbind(dfrc, dfrcval)
dfrcboth <- dfrcboth[- grep("TCGA_eset", rownames(dfrcboth)),]

# thanks Hmisc for messing up the Surv function
dfrcboth$y <- Surv(dfrcboth$y[,1], dfrcboth$y[,2])

# get dichotomized risk scores, not from the early stage samples
strata_we <-   do.call(rbind, lapply(c(res.lodo,res.val[-4]), function(x)
data.frame(x$strata, x$y)))
strata_tcga <-   do.call(rbind, lapply(c(res.lodo.tcga,res.val.tcga[-4]), function(x)
data.frame(x$strata, x$y)))


par(mfrow=c(2,2))
plotKM(y=dfrcboth$y, strata=factor(dfrcboth$tumorstage,levels=c(4,3)),censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="A)   Stage (4 vs. 3)")
plotKM(y=dfrcboth$y,strata=factor(dfrcboth$debulking_orig,levels=c("suboptimal", "optimal")),censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="B)   Debulking (subopt. vs opt.)")
plotKM(y=Surv(strata_tcga[,2][,1],strata_tcga[,2][,2]),
strata=strata_tcga[,1],censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="C)   TCGA Signature")

plotKM(y=Surv(strata_we[,2][,1],strata_we[,2][,2]),
strata=strata_we[,1],censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="D)   Meta-Analysis Signature")
@
}
\subfigure[]{
<<fpcomptcga,fig.width=5,fig.height=9,out.width="0.3\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
Xs.all <- esets.f[-8]
risk1a <- lapply(names(Xs.all), function(x) ma[[10]]$fits[[x]]$risk@lp)
risk1b <- lapply(esets.validation[-4], function(X) predict(final.model, X)@lp)

Xs.all <- c(Xs.all, esets.validation[-4])
risk1 <- c(risk1a, risk1b)

risk2 <- lapply(Xs.all, function(X) predict(model.tcga, X)@lp)

names(Xs.all) <- .getDatasetNames(Xs.all)
 x <- metaCMA.forest.models(Xs.all, risks1=risk1, risks2=risk2,
 graphwidth=unit(2.5, "inches"))
mtext("E)   Concordance",at=0,cex=1.4,font=2)

@
}
\caption{Comparison of our novel meta-analysis gene signature with existing
prognostic factors.
See caption in the main paper for details.}
\end{figure}

<<unocdiff, cache=TRUE>>=
res.c.delta.tcga <- Inf.Cval.Delta(cbind(as.numeric(dfrcboth$days_to_death), dfrcboth$vital_status=="deceased"), dfrcboth$risk_tcga, dfrcboth$risk,tau=365.25*4)
@

\begin{figure}
<<plotfpdebulking,fig.width=8,fig.height=6,out.width="0.9\\textwidth",out.height="0.675\\textwidth",results='hide'>>=
priors <- sapply(labels, function(l) sum(l=="suboptimal")/length(l))
 xxx <- .forestPlotDebulking(preds1=preds.logit,
  labels=labels[idx],
 prior=priors[idx],titles=titles[idx])
@
\caption{Predicting suboptimally debulked tumors. See caption in the main
paper for details.}
\end{figure}

\begin{figure}
<<plotdatasets,fig.width=7,fig.height=6,out.width="0.9\\textwidth",out.height="0.77\\textwidth",results='hide'>>=
par(mfrow=c(1,2))
.concPlotSize(esets.f, ma.sizes,dataset_ids=gsub(".Samples","",names(sizes)))
.concPlotSize(esets.f,
ma.sizes.rev,skip=1,dataset_ids=gsub(".Samples","",names(sizes.rev)),ylab="",panel.num="B)")
@
\caption{Prediction accuracy as a function of training datasets.
See caption in the main paper for details.}
\end{figure}

\clearpage
\section{Session Info}
<<sessioninfo, results='asis', echo=FALSE>>=
toLatex(sessionInfo())
@

\end{document}
