\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]{hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{booktabs}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
# this is equivalent to \SweaveOpts{...}
opts_chunk$set(fig.path='output/figures/metasig-', fig.align='center',
fig.show='hold',warning=FALSE, echo=FALSE)
options(replace.assign=TRUE,width=90)
@

\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{1}

\title{Risk Prediction for Late-stage Ovarian Cancer Using the Corpus of
Published Expression Data - Supplemental Figures}

\author{Markus Riester, Levi Waldron, Aedin Culhane, Lorenzo Trippa, \\
Curtis Huttenhower, Franziska Michor, Giovanni Parmigiani, Michael Birrer}
\maketitle

Code to reproduce all results presented in this paper is
available at \url{https://bitbucket.org/lima1/ovrc4_signew}.

\tableofcontents 

<<load, include=FALSE>>=
library(genefilter)
library(survival)
library(annotate)
library(hgu133a.db)
library(metafor)
library(ggplot2)
library(xtable)
library(survIDINRI)
library(ROCR)
library(RColorBrewer)
library(lattice)
library(maxstat)
library(exactRankTests)
library(pROC)
library(limma)
library(cvTools)
library(rockchalk)
library(GSVA)

# only to print the version number in the Appendix. We load the data generated
# with the createEsetsList script
library(curatedOvarianData)

source("src/metaCMA.R")
source("src/utils.R")
source("src/ggplot2extras.R")
# fixes a bug in the survcomp package
source("src/forestplot.surv.R")
@

% load the filtered expression data (run ./runEsetList.sh in the input
% directory
<<createesets, cache=TRUE>>=
load("input/eset.scaled.rda")
esets    <- esets[-match("GSE19829.GPL8300_eset",names(esets))]
@

<<percentstromaltcga>>=
# stromal contamination is not curated in our database, so fetch it from the
# official TCGA clinical data
x <- read.delim("input/Clinical/Biotab/biospecimen_slide_ov.txt", as.is=TRUE)
for (i in 1:length(esets)) esets[[i]]$percent_stromal_cells <- NA
esets$TCGA_eset$percent_stromal_cells <- as.numeric(x[match(sampleNames(esets$TCGA_eset),
    make.names(substr(x[,1],1,12))),"percent_stromal_cells"])
@

<<filtergenes, cache=TRUE>>=
# use only genes common to all platforms
esets.f  <- metaCMA.common.gene.esets(esets)
@

<<removeyoshihara>>=
# we added the Yoshihara data after we finalized our model, so remove it for
# now and use it later for validation
esets.uf <- esets
japan.idx <- match("GSE32062.GPL6480_eset",names(esets.f))
esets.f <- esets.f[-japan.idx]
@

<<loadvaldata,cache=TRUE>>=
# Now load all the other data.
load("input/eset.binary.scaled.rda")
esets.binary <- esets
load("input/eset.validation.scaled.rda")
esets.validation_orig <- esets
load("input/eset.allos.scaled.rda")
esets.allos <- esets
load("input/eset.debulking.scaled.rda")
esets.debulking <- esets
@

<<addearlystage>>=
# add the TCGA early stage samples to the validation data
ids <- esets.allos$TCGA_eset$summarystage=="early" &
    esets.allos$TCGA_eset$summarygrade!="low"
esets.validation <- c(esets.validation_orig, TCGA_eset=esets.allos$TCGA_eset[, ids])
@


<<loadtcga>>=
# Load the TCGA model from Levi's paper supplement
load("input/21720365-SuppTable_S6.RData")
model.tcga <- model.official
@

% calculate univariate Cox regression coefficients for each dataset and each
% gene
<<optimizecoefs, cache=TRUE>>=
coefs = metaCMA.coefs(esets.f)
@

% Do our leave-one-dataset-out cross-validation for different gene-signature
% sizes. 
<<optimizegrid, cache=TRUE,results='hide'>>=
ma = lapply(c(5,10,seq(25,250,25)), function(i)
    #metaCMA(esets.f,coefs=coefs,n=i,method="penalizedSurv",fold=5))
    metaCMA(esets.f,coefs=coefs,n=i))
@

\clearpage
\normalsize

\section{Dependency of gene signature size on prediction performance}

In all our analyses, we fixed the gene signature size to 200 genes. This size
was motivated by the fact that this size is sufficiently small to be
practically useful in a clinical test and by the performance of validated and
random signatures (Waldron et al, submitted). It was shown in Waldron et al.
that smaller signatures tend to be less robust than large signatures. Our
algorithm weighs genes according their rank (see Methods).  This means
increasing the signature size is expected to have only limited influence on
the prediction performance at some point as the weight of the genes decreases
consistently. In Supplemental Figure~\ref{fig:cutoff:train} we confirm that
the signature size had only modest impact on the prediction accuracy in our
algorithm, as long as the signature size was larger than 100 genes.  In this
figure, the prediction accuracy is reported with the C-Index metric. The
C-Index is a pairwise comparison of patients, summarizing the fraction of
pairs where the patient predicted to be at higher risk in fact has shorter
survival.  A C-Index of 0.5 would correspond to a random model, and a C-Index
of 1.0 of to a perfect model. Such a perfect model would predict the correct
order in which patients die. 

\begin{figure}[!htb]
<<validate, out.width='0.75\\textwidth', cache=TRUE>>=
.plotN <- function(esets, ma) {
    w <- sapply(esets,ncol)
    cidx = lapply(ma, function(x) sapply(1:length(esets), function(i)
        evaluate(x$fits[[i]]$risk, measure=new("UnoC"),
        newy=esets[[i]]$y,add=list(tau=365.25*4) )))

    dfCV <- stack(as.data.frame(do.call(rbind,cidx)))
    dfCV <- cbind(dfCV, Genes=c(5,10,seq(25,250,25)))
    dfCV$ind <- unlist(lapply(.getDatasetNames(esets), rep, 12))
    ggplot(dfCV, aes(values, Genes))+geom_point()+facet_wrap(~ind) +
    ylab("Number of Genes") + 
    xlab("C-Index (Concordance)") + 
    theme_classic(base_size=13) + 
    theme(axis.text.x=element_text(angle=45,hjust=1))
}
facetAdjust(.plotN(esets.f,ma))
@
\caption{In the \textit{leave-one-dataset-out} cross-validation in
\textbf{Figure 1-2}
of the main paper, we used a fixed gene signature size of 200 genes.  Here we
show the influence of this cutoff on the prediction concordance. Each point
represents the prediction concordance of a model with $y$ genes in the
corresponding dataset that was trained using the remaining datasets only.}
\label{fig:cutoff:train}
\end{figure}

% This now uses all datasets for calculating the final model.
<<finalmodel,cache=TRUE>>=
tmp <- metaCMA.opt(esets.f,coef=coefs,n=200)
final.model <- tmp$model
@

% Print the model for the supplement
<<tablemodel>>=
sig <- names(final.model@coefficients)
esets.f.all <- esets.f
esets.f.all$GSE32062.GPL6480_eset <- esets.validation$GSE32062.GPL6480_eset

probesets <- do.call(cbind, lapply(esets.f.all, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

write.csv(data.frame(Genes=sig, probesets, "Pooled Cox Coefficient"=
 final.model@coefficients,
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig))
), file="output/final_signature.csv",
row.names=FALSE)
@

\section{Best prediction accuracy is achieved in the TCGA immunoreactive
subtype}

In this section of the main paper, we showed the patient risk stratifications
in the 4 TCGA subtypes separately. Here we repeated the same analysis (i) in
TCGA only, using the official classification obtained from TCGA, (ii) in all
other datasets, which we classified in TCGA subtypes using the TCGA data for
training, and (iii) demonstrated consistent results using the alternative
classification proposed by the Australian Ovarian Cancer Study Group
(AOCS,\cite{Tothill:2008}). 

First we validated a prediction model that was trained on all training datasets except
TCGA in the 4 TCGA subtypes separately. Kaplan-Meier plots for this analysis
are shown in Supplemental Figure~\ref{fig:km:tcgasubtypes}. 

\begin{figure}[!htb]
<<subtypes, results='hide',out.width="0.7\\textwidth",out.height="0.7\\textwidth">>=
# this was obtained from a Broad mailing list, because the supplement refers
# to an internal link
subtypes <- read.delim("input/TCGA_489_UE.k4.txt")

esets.f$TCGA_eset$tcga_subtype_official <-
    subtypes[match(make.names(substr(esets.f$TCGA_eset$alt_sample_name,1,20)),
    subtypes[,1]),2]

# use the final model on TCGA. The C-Index will be biased, because TCGA was
# used for training. but we will get an idea in which subtype it works best
esets.f$TCGA_eset$risk <- predict(final.model, newdata=esets.f$TCGA_eset)@lp

# fetch the unbiased risk scores from the leave-one-dataset-out
# cross-validation
esets.f$TCGA_eset$risk_unbiased <- ma[[10]]$fits$TCGA_eset$risk@lp

cutpoint <- median(unlist(lapply(esets.f[-match("TCGA_eset",
 names(esets.f))], function(X) predict(ma[[10]]$fits$TCGA_eset$fit,
 newdata=X)@lp))) 

# no generate a forest plot for the unbiased risk scores
esets.tcga.subtypes <- lapply(levels(esets.f$TCGA_eset$tcga_subtype_official),function(s)
    esets.f$TCGA_eset[,!is.na(esets.f$TCGA_eset$tcga_subtype_official) &
    esets.f$TCGA_eset$tcga_subtype_official==s])
names(esets.tcga.subtypes) <- levels(esets.f$TCGA_eset$tcga_subtype_official)
par(mfrow=c(2,2))
par(mar=c(4.5, 4.1, 2.5, 1.5))
strata.subtypes <- lapply(1:length(esets.tcga.subtypes), function(i) plot(ma[[10]]$fits$TCGA_eset$fit,
newdata=esets.tcga.subtypes[[i]], newy=esets.tcga.subtypes[[i]]$y, 
        censor.at = 365.25*5, cutpoints=cutpoint, cex.base = 1.4, show.n.risk
        = FALSE, show.HR = TRUE, show.PV=FALSE, cex.HR=1.1,
        show.legend = FALSE, main = names(esets.tcga.subtypes)[i],
))
for (i in 1:4) 
esets.tcga.subtypes[[i]]$tcga_subtype <-
    esets.tcga.subtypes[[i]]$tcga_subtype_official 
@
\caption{Kaplan-Meier analysis of a model trained in all training datasets except TCGA and
then validated in TCGA in the 4 subtypes separately.}
\label{fig:km:tcgasubtypes}
\end{figure}

<<learnsubtypegenesets, cache=TRUE>>=
# here we use Limma to find gene sets for the TCGA subtype 
# we use again a default signature size of 200 (100 up and 100 down-regulated
# genes. The fold-change was chosen so that ~100 genes passed this filter with
# a FDR cutoff of 0.001.
X <- esets.f$TCGA_eset[, !is.na(esets.f$TCGA_eset$tcga_subtype_official)]
genesets <- .getFingerprintGeneSets(X, as.factor(X$tcga_subtype_official), p.value=0.001,
lfc=log2(1.45), number=100)
@

<<classifyesets,cache=TRUE,results='hide'>>=
gsva.res <- lapply(esets.f, function(X) .classifyGSVA(eset=X, genesets=genesets))
gsva.res.val <- lapply(esets.validation, function(X) .classifyGSVA(eset=X, genesets=genesets))
@

<<addsubtyping>>=
# get the subtype labels out of the GSVA results 
.fetchSubtypeGSVA <- function(i, esets, gsva, na.cutoff=0.1,
labels=levels(esets.f[[8]]$tcga_subtype_official) ) {
    tcga_subtype <- apply(gsva[[i]],2,which.max)
    # perfect enrichment score would be 2.0 and here we filter a few samples which
    # we really can't classify. This is still not very conservative, but does not
    # change much when I increase this threshold.
    tcga_subtype[apply(gsva[[i]],2,max) < na.cutoff] <- NA
    as.factor( labels[as.numeric(tcga_subtype)] )
}
for (i in 1:length(esets.f)) esets.f[[i]]$tcga_subtype <- .fetchSubtypeGSVA(i, esets.f, gsva.res)
for (i in 1:length(esets.validation)) {
    esets.validation[[i]]$percent_stromal_cells <- NA
    esets.validation[[i]]$tcga_subtype <-
        .fetchSubtypeGSVA(i, esets.validation, gsva.res.val)
}        

@

<<prepareclinicaldf, cache=TRUE>>=
# Create a data.frame that contains all relevant clinical information and
# the TCGA and our predictions.
X <- esets.uf[-japan.idx]
risk <- lapply(X, function(X) predict(model.tcga, newdata=X,
 type="lp")@lp)
X <- esets.f
for (i in 1:length(X)) {
    X[[i]]$risk_tcga <- risk[[i]]
    X[[i]]$risk <- ma[[10]]$fits[[i]]$risk@lp
}    
X <- X[-grep("TCGA",names(X))]
dfrc <- .createClinical(X)
dfrc$risk_tcga <- unlist(sapply(X, function(x) x$risk_tcga))
dfrc$risk <- unlist(sapply(X, function(x) x$risk))  
idx.stagedeb <- !is.na(dfrc$age) & !is.na(dfrc$debulking)
idx.stagedeb <- !is.na(dfrc$tumorstage) & !is.na(dfrc$debulking)
dfrc$debulking_orig <- dfrc$debulking
dfrc$debulking <- as.numeric(dfrc$debulking)
@

% make another data.frame with clinical information as signature risk scores,
% this time for the validation data
<<clinicalvalidation, cache=TRUE>>=
X <- esets.validation
dfrcval <- .createClinical(esets.validation)
dfrcval$percent_stromal_cells <- NA
for (i in 1:length(X)) X[[i]]$risk <- predict(model.tcga, newdata=X[[i]], type="lp")@lp
dfrcval$risk_tcga <- unlist(sapply(X, function(x) x$risk))
for (i in 1:length(X)) X[[i]]$risk <- predict(final.model, newdata=X[[i]], type="lp")@lp
dfrcval$risk <- unlist(sapply(X, function(x) x$risk))

dfrcval$debulking_orig <- dfrcval$debulking
@

<<accuracytcga>>=
x <- table(esets.f$TCGA_eset$tcga_subtype_official, esets.f$TCGA_eset$tcga_subtype)
x <- round(sum(sapply(1:4, function(i) x[i,i]))/sum(!is.na(esets.f$TCGA_eset$tcga_subtype_official))*100,digits=1)
@

We then classified all other training and validation datasets by subtype using
a single sample GSEA variant as implemented in the GSVA package. Subtype specific
gene sets were first identified with the limma package in the TCGA data using
the official TCGA subtype labels. We again used default gene set sizes of 200
genes for each subtype. Applied back to the TCGA data, this approach
classified \Sexpr{x}\% of the samples correctly. Note that TCGA used 
unified expression measures obtained from multiple platforms for training, not the
the Affymetrix data we used in our meta-analysis. In Supplemental
Figure~\ref{fig:km:subtypesos}, we show an association of subtype with overall
survival in all datasets except TCGA. The immunoreactive subtype had in both
TCGA and the remaining datasets the best prognosis. Poor survival was in
general observed for samples classified as mesenchymal. 

We then tested for consistent overlaps with the Australian Ovarian Cancer
Study Group (AOCS) subtypes as published by Tothill et al.
\cite{Tothill:2008}. All mesenchymal samples were assigned to the AOCS cluster
c1, which had poor prognosis in the Tothill data (Supplemental
Figures~\ref{fig:km:subtypesos}C and \ref{fig:overlap:aocstcga}). Most
immunoreactive samples were assigned to the c2 cluster and c2 samples had consistent
with our results better outcome in the Tothill dataset.

<<dfrcboth>>=
dfrcboth <- rbind(dfrc, dfrcval)
dfrcboth <- dfrcboth[!grepl("GenomeAtlas",dfrcboth$batch ),]

# thanks Hmisc for messing up the Surv function
dfrcboth$y <- Surv(dfrcboth$y[,1], dfrcboth$y[,2])
@

<<aocscomparison>>=
clinical.aocs <- read.xls("input/AOCS_subtytpes.xlsx", as.is=TRUE)
clinical.aocs$X <- toupper(gsub(".cel$","", clinical.aocs$X))
esets.f$GSE9891_eset$aocs_subtype <-
    as.factor(clinical.aocs$k[match(sampleNames(esets.f$GSE9891_eset),
    clinical.aocs$X)])

tbl.aocs <- table( esets.f$GSE9891_eset$aocs_subtype, 
    apply(gsva.res$GSE9891_eset,2,which.max))
colnames(tbl.aocs) <- rownames(gsva.res[[1]])
@


\begin{figure}[!htb]
<<subtypesother, results='hide',out.width="0.7\\textwidth",out.height="0.7\\textwidth">>=
par(mfrow=c(2,2))
par(mar=c(4.5, 4.1, 2.5, 1.5))
for (i in 1:4) {
tcga_subtype <- levels(esets.f$TCGA_eset$tcga_subtype_official)[i]
idx <- dfrcboth$tcga_subtype== tcga_subtype

plotKM(y=Surv(strata_we[idx,2][,1],strata_we[idx,2][,2]),
strata=strata_we[idx,1],censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main=tcga_subtype)
}        
@
\caption{Kaplan-Meier analysis of our overall survival signature as in Figures
4A of the main paper, but stratified by subtype as in Supplemental
Figure~\ref{fig:km:tcgasubtypes}.}
\label{fig:km:tcgasubtypesother}
\end{figure}

\begin{figure}
<<subtypesosdiff,fig.width=10,fig.height=10,out.width="0.96\\textwidth",out.height="0.96\\textwidth">>=
par(mar=c(5,5,3,2), mfrow=c(2,2))
plotKM(y=dfrcboth$y, strata=dfrcboth$tcga_subtype,
censor.at=365.25*5,main="A)  All datasets except TCGA")
plotKM(y=esets.f$TCGA_eset$y, strata=esets.f$TCGA_eset$tcga_subtype,
censor.at=365.25*5,main="B)  TCGA")
plotKM(y=esets.f$GSE9891_eset$y, strata=esets.f$GSE9891_eset$aocs_subtype,
censor.at=365.25*5,main="C)  AOCS Subtypes in Tothill et al.")
@
\caption{Association of subtype and overall survival.  (A) All training and
validation datasets excluding TCGA. (B) Stratification of TCGA samples by
subtype. (C) Kaplan-Meier curves of the subtypes proposed by the Australian
Ovarian Cancer Study Group (AOCS) in Tothill et al \cite{Tothill:2008}. This
analysis corresponds to Figure 5B of the Tothill study, with the difference that here
we show only the late-stage, high-grade, serous tumors used in our
meta-analysis.}
\label{fig:km:subtypesos}
\end{figure}

\begin{figure}
<<subtypesaocsoverlap,fig.width=10,fig.height=10,out.width="0.96\\textwidth",out.height="0.96\\textwidth">>=
heatmap.2(tbl,col=topo.colors,trace="none",margin=c(12,5))
@
\caption{Comparison AOCS and TCGA subtypes in Tothill et al
\cite{Tothill:2008}. Here
we compare our classification of Tothill samples in TCGA subtypes with
the official Tothill et al. clusters. The colors as indicated in the legend
on the upper left corner visualize the number of patients in the pairwise AOCS (rows)
and TCGA (columns) subtype combinations. For example, 35 patients of the AOCS
cluster c1 were classified as Mesenchymal.}
\label{fig:overlap:aocstcga}
\end{figure}


\clearpage
\section{The survival signature is superior to existing prognostic factors and
gene signatures}

We compared our overall survival prediction model to (i) a model using only
stage (III vs. IV) and debulking status (optimal vs.  suboptimal) and to (ii)
the TCGA prediction model as described in \cite{TCGA:2011}. In addition to the
comparison presented in the main paper, we compared models by the Integrated
Discrimination Improvement (IDI) reclassification measure \cite{Pencina:2008}
as implemented in the survIDINRI package \cite{Uno:2012}.  The IDI compares
two models to estimate whether one model provides an advantage over the other;
that is, whether it assigns higher risk to the patients who die within a
specified time compared to the competing model and a lower risk to patients
who do not die within this time frame. 

Finally, we compared the models by their C-Indices.  Statistical significance
of C-index differences between two models was estimated with the survC1 R
package \cite{Uno:2011}. Performance reports of test datasets always
correspond to leave-one-dataset-out cross-validated patient risk scores.

% Validate the TCGA model. Stolen from Levi's paper supplement.
<<validatetcgamodel, cache=TRUE,results='hide'>>=
data(TCGA_eset, package="curatedOvarianData")
featureNames(TCGA_eset) <- sub("-", "hyphen", featureNames(TCGA_eset))
TCGA_eset <- TCGA_eset[ ,!is.na(TCGA_eset$days_to_death) &
                                             !is.na(TCGA_eset$vital_status)]
TCGA_eset$y <- Surv(TCGA_eset$days_to_death / 30,
                               TCGA_eset$vital_status == "deceased")

TCGA.validation.eset <- TCGA_eset[ ,TCGA_eset$batch %in% c("17", "18", "19", "21", "22", "24")]
TCGA.training.eset   <- TCGA_eset[ ,TCGA_eset$batch >= 9 & TCGA_eset$batch <=
15 & !is.na(TCGA_eset$batch)]
##Validation set 2:
data(GSE9891_eset, package="curatedOvarianData")
featureNames(GSE9891_eset) <- sub("-", "hyphen", featureNames(GSE9891_eset))
GSE9891_eset <- GSE9891_eset[ ,!is.na(GSE9891_eset$days_to_death) &
                             !is.na(GSE9891_eset$vital_status)]
GSE9891_eset$y <- Surv(GSE9891_eset$days_to_death / 30, GSE9891_eset$vital_status == "deceased")

#Validation set 3, Bonome et al. (2008):
data(GSE26712_eset, package="curatedOvarianData")
featureNames(GSE26712_eset) <- sub("-", "hyphen", featureNames(GSE26712_eset))
GSE26712_eset <- GSE26712_eset[ ,!is.na(GSE26712_eset$days_to_death) &
                               !is.na(GSE26712_eset$vital_status)]
GSE26712_eset$y <- Surv(GSE26712_eset$days_to_death / 30,
                        GSE26712_eset$vital_status == "deceased")
data(PMID17290060_eset, package="curatedOvarianData")
featureNames(PMID17290060_eset) <- sub("-", "hyphen", featureNames(PMID17290060_eset))
PMID17290060_eset <- PMID17290060_eset[ ,!is.na(PMID17290060_eset$days_to_death) &
                                       !is.na(PMID17290060_eset$vital_status)]
PMID17290060_eset$y <- Surv(PMID17290060_eset$days_to_death / 30,
                            PMID17290060_eset$vital_status == "deceased")
@

\begin{figure}
<<reclassificationclinical,cache=TRUE,fig.width=12,fig.height=3,out.width="0.9\\textwidth",out.height="0.3\\textwidth",results='hide'>>=
par(mfrow=c(1,3))
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*1, 
title="All Training Datasets")
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*3, 
title="All Training Datasets")
.reclassPlot(dfrc[idx.stagedeb,"y"],dfrc[idx.stagedeb,c("tumorstage",
"debulking" )]
, dfrc[idx.stagedeb,c("tumorstage", "debulking","risk")]
, t0=365.25*5, 
title="All Training Datasets")
@
\caption{The additional value of our gene signature compared to age and
debulking status alone.  These plots visualize the Integrated Discrimination
Improvement (IDI, \cite{Pencina:2008,Uno:2012}), a measure of discrimination
of two competing nested survival models. Shown are plots for events within the
first 1, 3 and 5 years, respectively. The y-axis shows the probability that
the differences in predicted risk between the new and old models are smaller
than $s$, $P(D \leq s)$. The bold curve shows this probability for patients
who suffered from an event within the specified time, the thin line for those
who did not. The new model is better when patients with events have a higher
estimated risk (low probability that the risk difference is smaller than $s$)
and those without event a lower risk (high probability that risk difference is
smaller than $s$). The y-axis shows the discrimination improvement by varying
$s$, with the grey dots representing the IDI. See also \cite{Uno:2012} for a
more detailed explanation of these plots.  Our gene signature improved for all
three tested time points a model using only debulking status and age.} 
\label{fig:reclass}
\end{figure}

\begin{figure}
<<plotmodeltcgavalidation, results='hide'>>=
par(mfrow=c(2,2))

plot(model.tcga,newdata=TCGA.validation.eset,newy=TCGA.validation.eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="Overall Survival (%)",main="TCGA test set")

plot(model.tcga,newdata=GSE9891_eset,newy=GSE9891_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="",main="Tothill")
            
plot(model.tcga,newdata=GSE26712_eset,newy=GSE26712_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="Overall Survival (%)",main="Bonome")

plot(model.tcga,newdata=PMID17290060_eset,newy=PMID17290060_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="",main="Dressman")
@
\caption{TCGA model applied to the author test sets shown in Figure 2c of the TCGA paper
\cite{TCGA:2011}. The identical results show that our implementation of the
TCGA model is correct. Red survival curves correspond to high risk patients,
blue curves to low risk patients.}
\label{fig:tcga:reproduce}
\end{figure}

\begin{figure}
<<reclassification,cache=TRUE,fig.width=12,fig.height=3,out.width="0.9\\textwidth",out.height="0.3\\textwidth",results='hide'>>=
par(mfrow=c(1,3))
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25, 
title="All Training Datasets")
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25*3, 
title="All Training Datasets")
.reclassPlot(dfrc$y, dfrc$risk_tcga, dfrc$risk, t0=365.25*5, 
title="All Training Datasets")
@
\caption{Comparison of all \textit{leave-one-dataset-out} cross-validated risk
scores and the risk scores calculated by the TCGA model.  See
\textbf{Supplemental Figure~\ref{fig:reclass}} and \cite{Uno:2012} for an
explanation of these plots.  Shown are again plots for events within the first
1, 3 and 5 years, respectively. Our model shows a small but consistent
reclassification improvement over all three time points.}
\label{fig:reclass:tcga}
\end{figure}

% Calculate the C-Index differences
<<concdeltaclinical1, cache=TRUE>>=
res.dfrc <- Inf.Cval.Delta(cbind(as.numeric(dfrc$days_to_death[idx.stagedeb]),
dfrc$vital_status[idx.stagedeb]=="deceased"),
cbind(dfrc$tumorstage[idx.stagedeb], dfrc$debulking[idx.stagedeb] ), 
cbind(dfrc$tumorstage[idx.stagedeb],
dfrc$debulking[idx.stagedeb], dfrc$risk[idx.stagedeb]),tau=365.25*4)
@

<<concdeltaclinical2, cache=TRUE>>=
res.dfrc2 <- Inf.Cval.Delta(cbind(as.numeric(dfrc$days_to_death[idx.stagedeb]),
dfrc$vital_status[idx.stagedeb]=="deceased"),
dfrc$risk[idx.stagedeb],
cbind(dfrc$tumorstage[idx.stagedeb],
dfrc$debulking[idx.stagedeb], dfrc$risk[idx.stagedeb]),tau=365.25*4)
@
<<formatdeltac>>=
.formatDC <- function(conf) {
          conf <- sapply(conf, function(x) format(x, digits=2))
          dc <- paste(conf[1],"; 95\\% CI, ", conf[3], " - ",
                      conf[4], sep="")
}

@
\subsection{Comparison with clinicopathologic and demographic characteristics}

A model including both risk score and clinical variables was superior to a
model based on clinical factors alone. This was true both in terms of
concordance ($\Delta C$ \Sexpr{.formatDC(res.dfrc[3,])}) and reclassification
within the first 1, 3 and 5 years after diagnosis (Supplemental
Figure~\ref{fig:reclass}).  Finally, the combined model provided a modest
improvement over the gene signature alone ($\Delta C$
\Sexpr{.formatDC(res.dfrc2[3,])} in the six datasets with available clinical
factors.


\subsection{Comparison with the TCGA signature}

We then compared our signature to the TCGA signature. To apply the TCGA
signature across microarray platforms, we matched the 193 probe sets in the
signature to unique gene symbols used in curatedOvarianData \cite{Seal:2011};
this approach led to 185 unique genes involved in our signature.  We first
reproduced the reported performance of this model in the three TCGA test
datasets \cite{Bonome:2008,Dressman:2007,Tothill:2008} to ensure the
correctness of our model implementation (Supplemental
Figure~\ref{fig:tcga:reproduce}). Among the 200 genes in our signature, 19
overlapped with the TCGA signature (p < 0.001).  The probability of this
overlap between our and the TCGA signature was calculated with the
hypergeometric distribution, using the number of genes common to all training
datasets as background.  The C-Index of our signature compared to TCGA
improved moderately (\Sexpr{.formatDC(res.c.delta.tcga[3,])}). As random
signatures in ovarian cancer achieve a C-Index of 0.54 (Waldron et al.,
submitted), our signature represents a 33\% C-Index improvement over TCGA
compared to random signatures. 
\clearpage

\section{The survival signature predicts refractory cases}

\begin{figure}
<<elmeta,results='hide'>>=
Xs.all <- lapply(esets.f, .dichotomizeshortlong, l=365.25, label="os_1yr")
preds <- lapply(1:length(Xs.all), function(i) predict(ma[[10]]$fits[[i]]$fit,
newdata=Xs.all[[i]])@lp)
Xs.all <- c(Xs.all, lapply(esets.validation["GSE32062.GPL6480_eset"], .dichotomizeshortlong, l=365.25,
label="os_1yr"))
preds <- c(preds,lapply(length(Xs.all), function(i)
predict(final.model, newdata=Xs.all[[i]])@lp))

preds_tcga <- lapply(1:length(Xs.all), function(i) predict(model.tcga,
newdata=Xs.all[[i]])@lp)

labels <- lapply(Xs.all, function(X) X$os_1yr)
titles <- .getDatasetNames(Xs.all)
# remove TCGA again because we compare to the TCGA model
idx <- -8

aucs <- .plotROCpanel(preds[idx],labels[idx],titles[idx],3,3)
aucs_tcga <-
.plotROCpanel(preds_tcga[idx],labels[idx],titles[idx],2,3,plot=FALSE)
@
\caption{Prediction of refactory cases in a \textit{leave-one-dataset-out}
cross-validation.  Here the patient risk scores obtained by our overall
survival signature were used to predict events in the first year. ROC curves
visualize true and false positive rates for all possible risk score cutoffs.
The higher the score, the higher the probability the patient will die within
the first year. For each dataset, the overall survival signature was trained
using only the remaining datasets (Figure 1).}
\label{fig:roc:1yr}
\end{figure}

We evaluated the ability of our overall survival signature to predict
deaths within the first 12 months after diagnosis of the disease. This
endpoint was used as a surrogate for the presence of tumors refractory to
first-line adjuvant chemotherapy. In Supplemental Figure~\ref{fig:roc:1yr}, we
show ROC curves for our meta-analysis signature alone. The pooled AUC was
\Sexpr{.formatDC(aucs[c(1,2,5,6)])}, compared to 
\Sexpr{.formatDC(aucs_tcga[c(1,2,5,6)])} for the TCGA signature. 

<<oneyrfun, results='asis'>>=
df1yr <- .createClinical(Xs.all[idx], c("age_at_initial_pathologic_diagnosis",
"debulking","os_1yr", "tumorstage", "debulking", "days_to_death",
"vital_status"))
df1yr$os_1yr <- as.factor(df1yr$os_1yr)

df1yr$risk <- unlist(preds_tcga[idx])
fit_tcga <-
    glm(os_1yr~risk+age_at_initial_pathologic_diagnosis+debulking,data=df1yr,family="binomial")

df1yr$risk <- unlist(preds[idx])
fit <-
    glm(os_1yr~risk+age_at_initial_pathologic_diagnosis+debulking,data=df1yr,family="binomial")

fit_clinical <-
    glm(os_1yr~age_at_initial_pathologic_diagnosis+debulking,data=df1yr,family="binomial")

outreg(list(fit,fit_tcga), modelLabels=c("Meta-Analysis", "TCGA"),
title="Prediction of refractory cases. The table lists two logistic
regressions, one for our leave-one-dataset-out cross-validated meta-analysis gene signature, one for the TCGA
signature. The predictions from both models were adjusted for age and debulking
status. ", label="tbl:reg:1yr", tight=FALSE,
varLabels=list(risk="Gene Signature",debulkingsuboptimal="Debulking (Suboptimal)", 
age_at_initial_pathologic_diagnosis="Age"))

set.seed(1234)
aucs.adj <- repCV(fit, cost=ci.auc,R=10)
aucs_clinical.adj <- repCV(fit_clinical, cost=ci.auc,R=10)
res.ft <- fisher.test(dfrcboth$tcga_subtype=="Mesenchymal",
    dfrcboth$debulking_orig)
@

We then adjusted our gene signature risk score for age and debulking status
(Supplemental Table~\ref{ tbl:reg:1yr }). While significant, both our and the
TCGA signature provided only modest improvement over clinical factors in
predicting early events. In a five-fold cross-validation, the AUC 
of the 
multivariate model was \Sexpr{.formatDC(aucs.adj[[4]][c(2,1,1,3)])} compared to 
\Sexpr{.formatDC(aucs_clinical.adj[[4]][c(2,1,1,3)])} for a 
model utilizing only age and debulking status. We finally tested whether 
TCGA subtypes were associated with success of debulking surgery. Patients in
the mesenchymal subtype had the highest occurrence of suboptimal surgery (OR 
\Sexpr{.formatDC(c(res.ft$estimate,0,res.ft$conf.int))}). 

% Prepare the debulking datasets (use only genes common to all platforms)
<<debulkingmetaprepare>>=
Xs <- esets.debulking 
Xs.all <- metaCMA.common.gene.esets(Xs)
for (i in 1:length(Xs.all)) Xs.all[[i]]$debulking <- as.factor(Xs.all[[i]]$debulking)
Xs.alls34 <- Xs.all 
@

<<debulkingmetas34, cache=TRUE, results='hide'>>=
coefs.debulking.s34 <- metaCMA.coefs(Xs.alls34, y="debulking", family=binomial)
res.debulking.s34  <-
metaCMA(Xs.alls34,y="debulking",coefs=coefs.debulking.s34, n=200,
filter.fun=.debulkingFilter)
@
\section{A novel signature predicts suboptimal debulking surgery}

We generated a gene signature for suboptimal debulking surgery and validated
this signature by \textit{leave-one-dataset-out} cross-validation.  The
meta-analysis summary is shown in Supplemental
Figure~\ref{fig:forest:debulking} in a forest plot and Supplemental
Figure~\ref{fig:roc:debulking} are the corresponding ROC curves. In
Supplemental Table~\ref{ tbl:reg:debulking }, we show the logistic regression
coefficients of the gene signature risk score adjusted for FIGO stage (III vs.
IV). We also compared our results with the only published model predicting
debulking success \cite{Berchuck:2004} we were aware of, with the corresponding
forest plot shown in Supplemental Figure~\ref{fig:forest:debulking:berchuck04}.

<<debulkingmeta, cache=TRUE>>=
preds <- lapply(res.debulking.s34$fits,function(fit) fit$risk@lp)
labels <- lapply(Xs.alls34, function(X) X$debulking)
titles <- .getDatasetNames(Xs.alls34)
idx.debfi <- !sapply(Xs.alls34,.debulkingFilter)
@

\begin{figure}
<<plotfpdebulking,fig.width=9.5,fig.height=6,out.width="0.95\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
priors <- sapply(labels, function(l) sum(l=="suboptimal")/length(l))

 xxx <- .forestPlotDebulking(preds1=preds[idx.debfi],
  labels=labels[idx.debfi],
 prior=priors[idx.debfi],titles=titles[idx.debfi])
@
\caption{Predicting suboptimally debulked tumors. 
This figure lists the odds ratios (ORs) for  the predictions of our debulking
gene signature. The column \textit{debulking} lists the number of patients with
optimal and suboptimal debulking in each cohort. The OR for the gene signature
shows the odds of surgery failure for high-risk patients compared to low-risk
patients (see Supplemental Figure~\ref{fig:roc:debulking} for ROC curves).  The gene signature risk
score was obtained by a leave-one-dataset-out cross-validation as in Figure 1,
i.e., for each of the 8 datasets listed here, a prediction model was trained
using the remaining 7 datasets. The final signature trained on all 8 datasets
is shown in Supplemental Table 3.
}
\label{fig:forest:debulking}
\end{figure}


\begin{figure}
<<debulkingmetaplot, cache=TRUE>>=
preds <- lapply(res.debulking.s34$fits,function(fit) fit$risk@lp)
labels <- lapply(Xs.alls34, function(X) X$debulking)
titles <- .getDatasetNames(Xs.alls34)
idx.debfi <- !sapply(Xs.alls34,.debulkingFilter)
aucs.db <- .plotROCpanel(preds[idx.debfi],labels[idx.debfi],titles[idx.debfi],3,3)
@
\caption{Prediction of suboptimally debulked tumors in a leave-one-dataset-out
cross-validation. The prediction model calculates for each sample a score. The
higher the score, the higher the probability the tumor will be not optimally
debulkable. For each dataset, the model is trained using only the remaining
datasets. The model utilizes gene expression only (\textbf{Supplemental Table
2}). ROC curves visualize the true and false positive rates as a function of
the probability cutoffs.}  
\label{fig:roc:debulking}
\end{figure}

\begin{figure}
<<comparisonberchuck04, cache=TRUE,fig.width=9.5,fig.height=6,out.width="0.95\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
berchuck04 <- read.csv("input/berchuck04.csv",as.is=TRUE)
berchuck04.coefs <- berchuck04[,2]
names(berchuck04.coefs) <- berchuck04[,1]
model.berchuck04 <- new("linearriskscore", coefficients=berchuck04.coefs)
preds.berchuck04 <- lapply(esets.debulking, function(X) predict(model.berchuck04, newdata=X)@lp)
 xxx <- .forestPlotDebulking(preds1=preds.berchuck04[idx.debfi],
  labels=labels[idx.debfi],
 prior=priors[idx.debfi],titles=titles[idx.debfi])
@
\caption{Prediction of debulking status with the Berchuck et al. signature \cite{Berchuck:2004} as in Supplemental Figure~\ref{fig:forest:debulking}.}
\label{fig:forest:debulking:berchuck04}
\end{figure}

% Write the final debulking model to a spreadsheet.
<<finalmodeldebulking,cache=TRUE>>=
tmp <- metaCMA.opt(Xs.alls34, coefs=coefs.debulking.s34,n=200,y="debulking")
final.model.debulking <- tmp$model
sig <- names(final.model.debulking@coefficients)

probesets <- do.call(cbind, lapply(Xs.all, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

write.csv(data.frame(Genes=sig, probesets, 
"Pooled LogIt Coefficient"=
final.model.debulking@coefficients,
"Mean Optimal"= apply(tmp$train$X[which(tmp$train$y=="optimal"),],2,mean),
"Mean Suboptimal"= apply(tmp$train$X[which(tmp$train$y=="suboptimal"),],2,mean),
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig))),
 file="output/final_signature_debulking.csv",row.names=FALSE)
@
<<writemodelobjs>>=
save(final.model, final.model.debulking, file="output/models.rda")
@

<<debulkingadjust,results='asis', cache=TRUE>>=
dfrc.debulking <- .createClinical(Xs.alls34)
dfrc.debulking$risk <- unlist(preds.berchuck04)
fit.debulking.berchuck04 <-
    glm(debulking~risk+tumorstage,dfrc.debulking,family="binomial")

aucs.debulking.berchuck04 <- repCV(fit.debulking.berchuck04, cost=ci.auc,R=10)

dfrc.debulking$risk <- unlist(lapply(res.debulking.s34$fits, function(X)
X$risk@lp))

fit.debulking <-
    glm(debulking~risk+tumorstage,dfrc.debulking,family="binomial")

aucs.debulking <- repCV(fit.debulking, cost=ci.auc,R=10)

outreg(list(fit.debulking,fit.debulking.berchuck04), modelLabels=c("Meta-Analysis", "Berchuck et al. 2004"),
title="Prediction of debulking status. The table lists the
regression of our leave-one-dataset-out cross-validated meta-analysis
debulking gene signature
signature and the signature published by Berchuck et al. \\cite{Berchuck:2004}. The predictions were adjusted for tumor stage.",
label="tbl:reg:debulking", tight=FALSE,
varLabels=list(risk="Gene Signature",risk_berchuck04="Gene Signature",tumorstage="Stage (III vs IV)"))
@

<<finalmodeldebulkingfoldchanges, cache=TRUE>>=
load("input/eset.debulking.rda")
esets.db <- esets
esets.db <- esets.db[!sapply(esets.db, .debulkingFilter)]

res <- metaCMA.limma(lapply(esets.db, function(X)
    X[names(final.model.debulking@coefficients),]), "debulking",
    "suboptimal-optimal")
resM <- do.call(cbind, lapply(res, function(r) topTable(r,number=200,
    sort.by="none")[,2]))
resM <- cbind(resM, Weighted.Mean=apply(resM,1, weighted.mean, w=sqrt(sapply(
    esets.db, ncol))))
rownames(resM) <- names(final.model.debulking@coefficients)
resM <- cbind(resM,
FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig)))
resM <- resM[order(abs(resM[,ncol(resM)-1]),decreasing=TRUE),]
resM[,1:9] <- 2^resM[,1:9]
resM[,1:9] <- apply(resM[,1:9],c(1,2),function(x) ifelse(x<1, 1/(x*-1),x))

write.csv(resM, "output/final_signature_debulking_foldchanges.csv")
@
\clearpage
\begin{figure}
<<signgenes,cache=TRUE>>=
res.rcts <- lapply(esets.f, function(X) rowCoxTests(X, X$y))
nsig <- sapply(res.rcts, function(x) sum(x[,3] < 0.05))/nrow(esets.f[[1]])*100
d.f <- do.call(rbind, lapply(1:length(res.rcts), function(i)
 data.frame(Dataset=.getDatasetNames(esets.f)[i], P=res.rcts[[i]][,3])))

#ggplot(data.frame(Dataset=.getDatasetNames(esets.f), Genes=nsig),
#aes(Dataset,Genes))+geom_bar()+theme_classic()+theme(axis.text.x=element_text(angle=45,hjust=1))+
#ylab("Percentage of genes signficantly associated with OS (P < 0.05)")
facetAdjust(ggplot(d.f,aes(P))+geom_histogram(aes(y=..density..),binwidth=0.05)+facet_wrap(~Dataset)+xlab("Univariate Cox Regression P-values")+ylab("Density")+theme_classic()+geom_abline(intercept=1,slope=0,linetype="dashed"))
@
\caption{P-value distributions of association of mRNA expression with
overall survival (OS) for each gene in each dataset. For this plot, we
calculated for each training dataset and gene common to all platforms a
univariate Cox regression p-value. The dashed lines visualize a uniform
p-value distribution, the histograms the observed p-value distributions.}
\end{figure}

\clearpage
\bibliographystyle{plain}
\bibliography{metasig}
\newpage
\clearpage
\appendix
\section{Main Figures}
This supplement was generated with the knitr R package and contains the
complete analysis of this study. The source code is available at
\url{https://bitbucket.org/lima1/ovrc4_signew} to ease the reproducibility of
the study.  The following section generates the figures of the main paper.
\renewcommand{\thefigure}{\arabic{figure}}
\setcounter{figure}{0}

\begin{figure}
<<kmplotstrain,cache=TRUE,results='hide'>>=
res.lodo <- .lodocvPlot(esets.f, models=lapply(ma[[10]]$fits, function(x)
x$fit),ids=1:7)
res.lodo.tcga <- .lodocvPlot(esets.f, plot=FALSE,models=model.tcga,ids=1:7)
@
\caption{\textit{Leave-one-dataset-out} cross-validation of a novel gene signature for
predicting overall survival in late stage ovarian cancer.
See caption in the main paper for details.}
\end{figure}

<<datasetshr2prepare>>=
.allCombsEval <- function(ids, esets, object) {
       lodo <- .lodocvPlot(esets, models=object$fits[[1]]$fit, ids=ids,
       plot=FALSE)[[1]]
       fit <- coxph(lodo$y~lodo$strata)
       summary(fit)$coefficients
}
@

<<datasetshr2, cache=TRUE>>=
ret.hr <- lapply(1:length(esets.f), metaCMA.allcombinations, esets.f, n=200,eval.fun=.allCombsEval )
@

<<plotdatasetshrprepare>>=

df.hr <- do.call(rbind, lapply(1:length(esets.f),
function(i) data.frame(.getDatasetNames(esets.f)[i], unlist(ret.hr[[i]]$n),
  sapply(ret.hr[[i]]$evaluation, function(y) 1/y[2]))))
 
colnames(df.hr) <-c("Dataset", "n", "HR")

.psContains <- function(i, esets, s) {
    .doPS <- function(ps) {
        idx <- (1:length(esets))[-i][ps]
        ifelse(sum(grepl(s, names(esets)[idx]))>0, "Yes", "No")
     }
     pss <- metaCMA.powerset(length(esets[-i]))
     ret <- lapply(pss, .doPS)
}

df.hr$containstcga <- unlist(lapply(1:length(esets.f), .psContains, esets.f,"TCGA"))

df.hr <- df.hr[df.hr[,1]!="TCGA 2011",]

p <-ggplot(df.hr, aes(n,HR))+geom_smooth(method="lm")
#p <- p +geom_point(aes(shape=containstcga))
p <- p +geom_point(size=0.75)
p <- p +facet_wrap(~Dataset)+coord_cartesian(ylim= c(0.75, 2.9))+ylab("Hazard Ratio")+xlab("Total Training Sample Size")
#p <- p+ scale_shape(solid=FALSE, name = "TCGA used for training")
p <- p +theme(axis.text.x=element_text(angle=45,hjust=1))
@

\begin{figure}
<<tcgasubtypescombined,fig.width=7,fig.height=4.7,out.width="0.9\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
dfrc.subtypes <- .createClinical(c(esets.f[-8],esets.validation[-4],
 esets.tcga.subtypes), clinical.covars=c("days_to_death", "vital_status",
 "debulking", "tcga_subtype") )

dfrc.subtypes$strata <- c(strata_we[,1], unlist(sapply(strata.subtypes, function(x)
  x$strata)))
dfrc.subtypes$strata <- as.factor( levels(strata_we[,1])[
as.numeric(dfrc.subtypes$strata)
] )

par(mfrow=c(2,3))
par(mar=c(4.5, 4.1, 2.5, 1.5))

for (i in 1:4) {
    tcga_subtype <- levels(esets.f$TCGA_eset$tcga_subtype_official)[i]
    idx <- dfrc.subtypes$tcga_subtype== tcga_subtype

    plotKM(y=dfrc.subtypes[idx,"y"],
    strata=dfrc.subtypes$strata[idx],censor.at=365.25*5,
            show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,
            show.PV=FALSE, cex.HR=0.88,
            cex.base=1.4,cex.legend=1.1,main=paste(toupper(letters[i]), ") ", tcga_subtype, sep=""))
}        

plotKM(y=dfrc.subtypes$y, strata=dfrc.subtypes$tcga_subtype,censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=TRUE,show.HR=FALSE,
        cex.base=1.4,cex.legend=0.75,main="E) TCGA subtypes")
@
\caption{TCGA subtypes. 
See caption in the main paper for details.}
\end{figure}


\begin{figure}
<<validationexternal,cache=TRUE,fig.width=7,fig.height=4.7,out.width="0.9\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
res.val <- .valPlot(final.model)
res.val.tcga <- .valPlot(model.tcga, plot=FALSE)
@
\caption{Validation of the final signature in independent data. 
See caption in the main paper for details.}
\end{figure}

\begin{figure}
\subfigure[]{
<<comptcga,fig.width=7,fig.height=7,out.width="0.6\\textwidth",out.height="0.6\\textwidth",results='hide'>>=


# get dichotomized risk scores, not from the early stage samples
strata_we <-   do.call(rbind, lapply(c(res.lodo,res.val[-4]), function(x)
data.frame(x$strata, x$y)))
strata_tcga <-   do.call(rbind, lapply(c(res.lodo.tcga,res.val.tcga[-4]), function(x)
data.frame(x$strata, x$y)))


par(mfrow=c(2,2))
par(mar=c(4.5, 4.1, 2.5, 1.5))
plotKM(y=Surv(strata_we[,2][,1],strata_we[,2][,2]),
strata=strata_we[,1],censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="A)   Meta-Analysis Signature")
plotKM(y=Surv(strata_tcga[,2][,1],strata_tcga[,2][,2]),
strata=strata_tcga[,1],censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="B)   TCGA Signature")
plotKM(y=dfrcboth$y,strata=factor(dfrcboth$debulking_orig,levels=c("suboptimal", "optimal")),censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="C)   Debulking (subopt. vs opt.)")
plotKM(y=dfrcboth$y, strata=factor(dfrcboth$tumorstage,levels=c(4,3)),censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",ylab="Overall Survival (%)",
        cex.base=1.4,main="D)   Stage (4 vs. 3)")
@
}
\subfigure[]{
<<fpcomptcga,fig.width=5.75,fig.height=9,out.width="0.4\\textwidth",out.height="0.6\\textwidth",results='hide'>>=
Xs.all <- c(esets.f[-8], esets.validation[-4])
names(Xs.all) <- .getDatasetNames(Xs.all)

res.strata <- lapply(c(res.lodo, res.val[-4]), function(x) x$strata)
res.strata.tcga <- lapply(c(res.lodo.tcga, res.val.tcga[-4]), function(x) x$strata)

x <- metaCMA.forest.models(metaCMA.censor(Xs.all,censor.at=365.25*5), risks1=res.strata, risks2=res.strata.tcga,
 graphwidth=unit(2.5,
 "inches"),concordance=FALSE,inverse=TRUE,x.ticks=c(0.5,1,2,4,8),clip=log(c(0.5,8)))
mtext("E)",cex=1.4,font=2)
@
}
\caption{Comparison of our novel meta-analysis gene signature with existing
prognostic factors.
See caption in the main paper for details.}
\end{figure}

<<unocdiff, cache=TRUE>>=
res.c.delta.tcga <- Inf.Cval.Delta(cbind(as.numeric(dfrcboth$days_to_death), dfrcboth$vital_status=="deceased"), dfrcboth$risk_tcga, dfrcboth$risk,tau=365.25*4)
@


<<hrdiffconfint, cache=TRUE>>=
d.f <- data.frame( do.call(rbind,lapply(metaCMA.censor(Xs.all,censor.at=365.25*5), function(X) X$y)),
strata=strata_we[,1], strata_tcga=strata_tcga[,1])

hrdiffemp <- .boostrapHRs(d.f,n=10000,inverse=TRUE)
hrdiffci <- quantile(hrdiffemp,c(0.025,0.975))
@

\begin{figure}
<<plotdatasetshr, cache=TRUE>>=
facetAdjust(p+theme_classic(14)+theme(axis.text.x = element_text(angle = 45, hjust = 1)))
@
\caption{Hazard Ratios as a function of training sample size.
See caption in the main paper for details.}
\end{figure}


\clearpage
\section{Session Info}
<<sessioninfo, results='asis', echo=FALSE>>=
toLatex(sessionInfo())
@

\end{document}
