\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]{hyperref}
\hypersetup{pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage[parfill]{parskip}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
# this is equivalent to \SweaveOpts{...}
opts_chunk$set(fig.path='output/figures/metasig-', fig.align='center',
fig.show='hold',warning=FALSE, echo=FALSE)
options(replace.assign=TRUE,width=90)
@

\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{1}

\title{Risk Prediction for Late-stage Ovarian Cancer Using the Corpus of
Published Expression Data - Supplemental Figures}

\author{Markus Riester, Levi Waldron, Aedin Culhane, Lorenzo Trippa, \\
Curtis Huttenhower, Franziska Michor, Giovanni Parmigiani, Michael Birrer}
\maketitle

Code to reproduce all results presented in this paper is
available at \url{https://bitbucket.org/lima1/ovrc4_signew}.

\tableofcontents 

<<load, include=FALSE>>=
library(genefilter)
library(survival)
library(annotate)
library(hgu133a.db)
library(metafor)
library(ggplot2)
library(xtable)
library(survIDINRI)
library(ROCR)
library(RColorBrewer)
library(lattice)
library(maxstat)
library(exactRankTests)
library(pROC)
library(limma)
library(cvTools)
library(rockchalk)
library(GSVA)
library(ez)
library(sampling)
library(impute)

# only to print the version number in the Appendix. We load the data generated
# with the createEsetsList script
library(curatedOvarianData)

source("src/metaCMA.R")
source("src/utils.R")
source("src/ggplot2extras.R")
# fixes a bug in the survcomp package
source("src/forestplot.surv.R")
@

% load the filtered expression data (run ./runEsetList.sh in the input
% directory
<<cached_short_createesets, cache=TRUE>>=
load("input/eset.scaled.rda")
esets    <- esets[-match("GSE19829.GPL8300_eset",names(esets))]
@

<<removeduplicates>>=
# 10 Bonome samples were included in TCGA late-stage, high grade serous
btdups <- read.xls("input/bonometcgaduplicates.xls", as.is=TRUE)
btdups <- btdups[btdups[,1] %in%
            make.names(esets$TCGA_eset$unique_patient_ID),]

@

<<changedebulkingtcga>>=
# remove Bonome samples, change debulking definition
.fixTCGA <- function(esets) {
    esets$TCGA_eset <- esets$TCGA_eset[,-na.omit(match(btdups[,1],
        make.names(esets$TCGA_eset$unique_patient_ID)))]

    .debulkingTCGA <- function(eset) {
        debulking <- sapply(sapply(strsplit(eset$uncurated,
        "///"), function(x) x[grep("tumor_residual_disease: ",x)]),function(y)
        y[[1]])
        tmp <- debulking
        idx <- debulking == "tumor_residual_disease: No Macroscopic disease"
        debulking[idx] <- "optimal"
        debulking[!idx] <- "suboptimal"
        debulking[tmp == "tumor_residual_disease: NA"] <- NA
        as.factor(debulking)
    }

    esets$TCGA_eset$debulkingold <-  esets$TCGA_eset$debulking

    # change TCGA debulking definition to no macroscopic disease
    esets$TCGA_eset$debulking <-  as.vector(.debulkingTCGA(esets$TCGA_eset))
    esets
}

esets <- .fixTCGA(esets)
@

<<cached_short_filtergenes, cache=TRUE>>=
# use only genes common to all platforms
esets.f  <- metaCMA.common.gene.esets(esets)
@

<<removeyoshihara>>=
# we added the Yoshihara data after we finalized our model, so remove it for
# now and use it later for validation
esets.uf <- esets
japan.idx <- match("GSE32062.GPL6480_eset",names(esets.f))
esets.f <- esets.f[-japan.idx]
@


<<cached_short_loadvaldata,cache=TRUE>>=
# Now load all the other data.
load("input/eset.binary.scaled.rda")
esets.binary <- esets
load("input/eset.validation.scaled.rda")
esets.validation_orig <- esets
load("input/eset.allos.scaled.rda")
esets.allos <- esets
load("input/eset.debulking.scaled.rda")
esets.debulking <- esets
@

<<changedebulkingtcga2>>=
esets.debulking <- .fixTCGA(esets.debulking)
esets.allos <- .fixTCGA(esets.allos)
@

<<addearlystage>>=
# add the TCGA early stage samples to the validation data
ids <- esets.allos$TCGA_eset$summarystage=="early" &
    esets.allos$TCGA_eset$summarygrade!="low"
esets.validation <- c( esets.validation_orig, TCGA_eset=esets.allos$TCGA_eset[, ids] )
@

<<loadtcga>>=
# Load the TCGA model from Levi's paper supplement
load("input/21720365-SuppTable_S6.RData")
model.tcga <- model.official
@

<<cached_short_loadjci, cache=TRUE>>=
# create the CLOVAR model from their supplement. They use the same TCGA
# algorithm
jci.sig <- read.xls("input/JCI65833sd1.xls", sheet=3, skip=1, as.is=TRUE)
jci.coefs <- ifelse(jci.sig$CLASS=="GOOD",-1,1)
names(jci.coefs) <- jci.sig$Gene.Symbol
model.jci <- new("linearriskscore", coefficients=jci.coefs, modeltype="tscore")
@

% calculate univariate Cox regression coefficients for each dataset and each
% gene
<<optimizecoefs, cache=TRUE>>=
coefs <- metaCMA.coefs(esets.f)
@

% Do our leave-one-dataset-out cross-validation for different gene-signature
% sizes. 
<<optimizegrid, cache=TRUE,results='hide'>>=
ma <- lapply(c(5,10,seq(25,250,25)), function(i)
    #metaCMA(esets.f,coefs=coefs,n=i,method="penalizedSurv",fold=5))
    metaCMA(esets.f,coefs=coefs,n=i))
@

\clearpage
\normalsize

\section{Dependency of gene signature size on prediction performance}

In all our analyses, we fixed the gene signature size to 200 genes. This size
was motivated by the fact that this size is sufficiently small to be
practically useful in a clinical test and by the performance of validated and
random signatures (Waldron et al, submitted). It was shown in Waldron et al.
that smaller signatures tend to be less robust than large signatures. Our
algorithm weighs genes according their rank (see Methods).  This means
increasing the signature size is expected to have only limited influence on
the prediction performance at some point as the weight of the genes decreases.

In Supplemental Figure~\ref{fig:cutoff:train} we confirm that the signature
size had only modest impact on the prediction accuracy in our algorithm, as
long as the signature size was larger than 100 genes.  In this figure, the
prediction accuracy is reported with the C-Index metric. The C-Index is a
pairwise comparison of patients, summarizing the fraction of pairs where the
patient predicted to be at higher risk in fact has shorter survival.  A
C-Index of 0.5 would correspond to a random model, and a C-Index of 1.0 of to
a perfect model. Such a perfect model would predict the correct order in which
patients die. We chose this performance measure here instead of Hazard Ratios
because it has an easy interpretation, is essentially parameter free and does
not require a dichotomization of the prediction scores.

\begin{figure}[!htb]
<<cached_short_validate, out.width='0.75\\textwidth', cache=TRUE>>=
.plotN <- function(esets, ma) {
    w <- sapply(esets,ncol)
    cidx = lapply(ma, function(x) sapply(1:length(esets), function(i)
        evaluate(x$fits[[i]]$risk, measure=new("UnoC"),
        newy=esets[[i]]$y,add=list(tau=365.25*4) )))

    dfCV <- stack(as.data.frame(do.call(rbind,cidx)))
    dfCV <- cbind(dfCV, Genes=c(5,10,seq(25,250,25)))
    dfCV$ind <- unlist(lapply(.getDatasetNames(esets), rep, 12))
    ggplot(dfCV, aes(Genes, values))+geom_point()+facet_wrap(~ind) +
    xlab("Number of Genes") + 
    ylab("C-Index (Concordance)") + 
    theme_classic(base_size=13) + 
    theme(axis.text.x=element_text(angle=45,hjust=1))
}
facetAdjust(.plotN(esets.f,ma))
@
\caption{We used for all our gene signatures a fixed gene signature size of
200 genes. Here we show the influence of this cutoff on the prediction
concordance of the overall survival signature. Each point represents the
prediction concordance of a model with $x$ genes in the corresponding dataset
that was trained using the remaining datasets only.}
\label{fig:cutoff:train}
\end{figure}

% This now uses all datasets for calculating the final model.
<<cached_short_finalmodel,cache=TRUE>>=
tmp <- metaCMA.opt(esets.f,coef=coefs,n=200)
final.model <- tmp$model
@

<<tablemodel>>=
# Print the model for the supplement
sig <- names(final.model@coefficients)
esets.f.all <- esets.f
esets.f.all$GSE32062.GPL6480_eset <- esets.validation$GSE32062.GPL6480_eset

probesets <- do.call(cbind, lapply(esets.f.all, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

write.csv(data.frame(Genes=sig, probesets, "Pooled Cox Coefficient"=
 final.model@coefficients,
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig))
), file="output/final_signature.csv",
row.names=FALSE)
@

<<tcgasubtypes>>=
# get the official TCGA subtype labels and add it to the eset
# this was obtained from a Broad mailing list, because the supplement refers
# to an internal link
subtypes <- read.delim("input/TCGA_489_UE.k4.txt")

esets.f$TCGA_eset$tcga_subtype_official <-
    subtypes[match(make.names(substr(esets.f$TCGA_eset$alt_sample_name,1,20)),
    subtypes[,1]),2]
@

<<learnsubtypegenesets, cache=TRUE>>=
# here we use Limma to find gene sets for the TCGA subtype 
# we use again a default signature size of 200 (100 up and 100 down-regulated
# genes. The fold-change was chosen so that ~100 genes passed this filter with
# a FDR cutoff of 0.001.
X <- esets.f$TCGA_eset[, !is.na(esets.f$TCGA_eset$tcga_subtype_official)]
genesets <- .getFingerprintGeneSets(X, as.factor(X$tcga_subtype_official), p.value=0.001,
lfc=log2(1.45), number=100)
@

<<classifyesets,cache=TRUE,results='hide'>>=
gsva.res <- lapply(esets.f, function(X) .classifyGSVA(eset=X, genesets=genesets))
gsva.res.val <- lapply(esets.validation, function(X) .classifyGSVA(eset=X, genesets=genesets))
@

<<addsubtyping>>=
# get the subtype labels out of the GSVA results 
.fetchSubtypeGSVA <- function(i, esets, gsva, na.cutoff=0.1,
labels=levels(esets.f[[8]]$tcga_subtype_official) ) {
    tcga_subtype <- apply(gsva[[i]],2,which.max)
    # perfect enrichment score would be 2.0 and here we filter a few samples which
    # we really can't classify. This is still not very conservative, but does not
    # change much when I increase this threshold.
    tcga_subtype[apply(gsva[[i]],2,max) < na.cutoff] <- NA
    as.factor( labels[as.numeric(tcga_subtype)] )
}
for (i in 1:length(esets.f)) esets.f[[i]]$tcga_subtype <- .fetchSubtypeGSVA(i, esets.f, gsva.res)
for (i in 1:length(esets.validation)) {
    esets.validation[[i]]$tcga_subtype <-
        .fetchSubtypeGSVA(i, esets.validation, gsva.res.val)
}        

@

<<cached_short_prepareclinicaldf, cache=TRUE>>=
# Create a data.frame that contains all relevant clinical information and
# the TCGA and our predictions. Use esets.uf, because esets.f contains only
# probesets common to all platforms.
X <- esets.uf[-japan.idx]
risk_tcga <- lapply(X, function(X) predict(model.tcga, newdata=X, type="lp")@lp)
risk_jci <- lapply(X, function(X) predict(model.jci, newdata=X, type="lp")@lp)
X <- esets.f
for (i in 1:length(X)) {
    X[[i]]$risk_tcga <- risk_tcga[[i]]
    X[[i]]$risk_jci  <- risk_jci[[i]]
    X[[i]]$risk <- ma[[10]]$fits[[i]]$risk@lp
}    
X <- X[-grep("TCGA",names(X))]
dfrc <- .createClinical(X)
dfrc$risk_tcga <- unlist(sapply(X, function(x) x$risk_tcga))
dfrc$risk_jci <- unlist(sapply(X, function(x) x$risk_jci))
dfrc$risk <- unlist(sapply(X, function(x) x$risk))  
idx.stagedeb <- !is.na(dfrc$age) & !is.na(dfrc$debulking)
idx.stagedeb <- !is.na(dfrc$tumorstage) & !is.na(dfrc$debulking)
dfrc$debulking_orig <- dfrc$debulking
dfrc$debulking <- as.numeric(dfrc$debulking)
@

<<cached_short_clinicalvalidation, cache=TRUE>>=
# make another data.frame with clinical information as signature risk scores,
# this time for the validation data
X <- esets.validation
dfrcval <- .createClinical(esets.validation)
for (i in 1:length(X)) X[[i]]$risk <- predict(model.tcga, newdata=X[[i]], type="lp")@lp
dfrcval$risk_tcga <- unlist(sapply(X, function(x) x$risk))
for (i in 1:length(X)) X[[i]]$risk <- predict(model.jci, newdata=X[[i]], type="lp")@lp
dfrcval$risk_jci <- unlist(sapply(X, function(x) x$risk))
for (i in 1:length(X)) X[[i]]$risk <- predict(final.model, newdata=X[[i]], type="lp")@lp
dfrcval$risk <- unlist(sapply(X, function(x) x$risk))

dfrcval$debulking_orig <- dfrcval$debulking
@

<<dfrcboth>>=
# combine both leave-one-dataset-out validation and independent validation in
# one easy to work with data.frame
dfrcboth <- rbind(dfrc, dfrcval)
dfrcboth <- dfrcboth[!grepl("GenomeAtlas",dfrcboth$batch ),]

# thanks Hmisc for messing up the Surv function
dfrcboth$y <- Surv(dfrcboth$y[,1], dfrcboth$y[,2])

# add the ssGSEA subtype scores as covariates to the data.frame
g <- do.call(cbind, lapply(1:4, function(st)
 unlist(lapply(c(gsva.res[-8],gsva.res.val[-4]), function(x) x[st,]))))
colnames(g) <-  rownames(gsva.res[[1]])
dfrcboth <- data.frame(dfrcboth, g)
@

<<cached_short_figure1,cache=TRUE,fig.width=7,fig.height=4.7,out.width="0.9\\textwidth",out.height="0.6\\textwidth",results='hide',include=FALSE>>=
res.lodo <- .lodocvPlot(esets.f, models=lapply(ma[[10]]$fits, function(x)
    x$fit),ids=1:8)[-8]
res.lodo.tcga <- .lodocvPlot(esets.f, plot=FALSE,models=model.tcga,ids=1:7)
res.lodo.jci <- .lodocvPlot(esets.f, plot=FALSE,models=model.jci,ids=1:7)
@

<<cached_short_validationexternal,cache=TRUE,results='hide', include=FALSE>>=
res.val <- .valPlot(final.model)
res.val.tcga <- .valPlot(model.tcga, plot=FALSE)
res.val.jci <- .valPlot(model.jci, plot=FALSE)
@

<<addtodfrcboth>>=
# here we add the patient stratifications (high-risk vs low-risk) to the data.frame
dfrcboth$strata <-  unlist(lapply(c(res.lodo,res.val[-4]), function(x)
    x$strata))

dfrcboth$strata_tcga <-  unlist(lapply(c(res.lodo.tcga,res.val.tcga[-4]), function(x)
    x$strata))

dfrcboth$strata_jci <-  unlist(lapply(c(res.lodo.jci,res.val.jci[-4]), function(x)
    x$strata))
@

\clearpage

\section{Comparison with the TCGA signatures}

We then compared our signature to the TCGA signature \cite{TCGA:2011}. To
apply the TCGA signature across microarray platforms, we matched the 193 probe
sets in the signature to unique gene symbols \cite{Seal:2011} used in
curatedOvarianData; this approach led to 185 unique genes involved in our
signature.  We first reproduced the reported performance of this model in the
three TCGA test datasets \cite{Bonome:2008,Dressman:2007,Tothill:2008} to
ensure the correctness of our model implementation (Supplemental
Figure~\ref{fig:tcga:reproduce}). Among the 200 genes in our signature, 17
overlapped with the TCGA signature ($P < 0.001$).  The p-value of this overlap
between our and the TCGA signature was calculated with the hypergeometric
distribution, using the number of genes common to all training datasets as
background.  

The TCGA project recently published an improved gene signature called CLOVAR
\cite{Verhaak:2013}. We could map 87 of the 100 genes of the signature to
probesets used curatedOvarianData. 21 of these genes overlapped with our gene
signature ($P < 0.001$). The correlation of the risk scores of our
meta-analysis signature and both TCGA signatures are shown in Supplemental
Figure~\ref{fig:cor:risk}. 

% Validate the TCGA model. Stolen from Levi's paper supplement.
<<cached_short_validatetcgamodel, cache=TRUE,results='hide'>>=
data(TCGA_eset, package="curatedOvarianData")
featureNames(TCGA_eset) <- sub("-", "hyphen", featureNames(TCGA_eset))
TCGA_eset <- TCGA_eset[ ,!is.na(TCGA_eset$days_to_death) &
                                             !is.na(TCGA_eset$vital_status)]
TCGA_eset$y <- Surv(TCGA_eset$days_to_death / 30,
                               TCGA_eset$vital_status == "deceased")

TCGA.validation.eset <- TCGA_eset[ ,TCGA_eset$batch %in% c("17", "18", "19", "21", "22", "24")]
TCGA.training.eset   <- TCGA_eset[ ,TCGA_eset$batch >= 9 & TCGA_eset$batch <=
15 & !is.na(TCGA_eset$batch)]
##Validation set 2:
data(GSE9891_eset, package="curatedOvarianData")
featureNames(GSE9891_eset) <- sub("-", "hyphen", featureNames(GSE9891_eset))
GSE9891_eset <- GSE9891_eset[ ,!is.na(GSE9891_eset$days_to_death) &
                             !is.na(GSE9891_eset$vital_status)]
GSE9891_eset$y <- Surv(GSE9891_eset$days_to_death / 30, GSE9891_eset$vital_status == "deceased")

#Validation set 3, Bonome et al. (2008):
data(GSE26712_eset, package="curatedOvarianData")
featureNames(GSE26712_eset) <- sub("-", "hyphen", featureNames(GSE26712_eset))
GSE26712_eset <- GSE26712_eset[ ,!is.na(GSE26712_eset$days_to_death) &
                               !is.na(GSE26712_eset$vital_status)]
GSE26712_eset$y <- Surv(GSE26712_eset$days_to_death / 30,
                        GSE26712_eset$vital_status == "deceased")
data(PMID17290060_eset, package="curatedOvarianData")
featureNames(PMID17290060_eset) <- sub("-", "hyphen", featureNames(PMID17290060_eset))
PMID17290060_eset <- PMID17290060_eset[ ,!is.na(PMID17290060_eset$days_to_death) &
                                       !is.na(PMID17290060_eset$vital_status)]
PMID17290060_eset$y <- Surv(PMID17290060_eset$days_to_death / 30,
                            PMID17290060_eset$vital_status == "deceased")
@

\begin{figure}
<<plotmodeltcgavalidation, results='hide'>>=
par(mfrow=c(2,2))

plot(model.tcga,newdata=TCGA.validation.eset,newy=TCGA.validation.eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="Overall Survival (%)",main="TCGA test set")

plot(model.tcga,newdata=GSE9891_eset,newy=GSE9891_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="",ylab="",main="Tothill")
            
plot(model.tcga,newdata=GSE26712_eset,newy=GSE26712_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="Overall Survival (%)",main="Bonome")

plot(model.tcga,newdata=PMID17290060_eset,newy=PMID17290060_eset$y,censor.at=60,
            cex.base=1.4,show.n.risk=FALSE, show.HR=FALSE,
            show.legend=FALSE,xlab="Time (Months)",ylab="",main="Dressman")
@
\caption{TCGA model applied to the author test sets shown in Figure 2c of the TCGA paper
\cite{TCGA:2011}. The identical results show that our implementation of the
TCGA model is correct. Red survival curves correspond to high risk patients,
blue curves to low risk patients.}
\label{fig:tcga:reproduce}
\end{figure}

\clearpage

\begin{figure}
<<correlationriskscores>>=
X <- dfrcboth[,c("risk", "risk_tcga", "risk_jci")]
colnames(X) <- c("Meta-Analysis", "TCGA", "Verhaak et al.")
ezCor(X, label_size=7)
@
\caption{Pairwise correlation of the gene signature risk scores for the
Meta-Analysis, TCGA and Verhaak et al. signatures.  Numbers in the
upper-right, tringular half of the matrix are the Pearson correlation
coefficients, which were all statistically significant ($P < 0.05$). Pairwise
scatterplots of expression values are shown in the lower-left half and the
expression histograms are shown on the matrix diagonal.}
\label{fig:cor:risk}
\end{figure}

\clearpage

\section{Comparison with the CLOVAR multivariate model}

<<accuracytcga>>=
x <- table(esets.f$TCGA_eset$tcga_subtype_official, esets.f$TCGA_eset$tcga_subtype)
x <- round(sum(sapply(1:4, function(i) x[i,i]))/sum(!is.na(esets.f$TCGA_eset$tcga_subtype_official))*100,digits=1)
@

We classified all datasets by TCGA subtype using a single sample GSEA variant
as implemented in the GSVA package. Subtype specific gene sets were first
identified with the limma package in the TCGA data using the official TCGA
subtype labels. Final subtype scores were obtained by subtracting the ssGSEA
scores for the down-regulated gene sets from the up-regulated genes. We again
used default gene set sizes of 200 genes for each subtype (100 up- and 100
down-regulated genes per subtype). Applied back to the TCGA data, this
approach classified \Sexpr{x}\% of the samples correctly. Note that TCGA used
unified expression measures obtained from multiple platforms for training, not
the Affymetrix data we used in our meta-analysis. In Supplemental
Figure~\ref{fig:km:subtypesos}, we show an association of subtype with overall
survival in all datasets except TCGA consistent with the report of Verhaak et
al. \cite{Verhaak:2013}. The immunoreactive subtype had in both
TCGA and the remaining datasets the best prognosis. Poor survival was in
general observed for samples classified as mesenchymal. 

<<aocscomparison>>=
clinical.aocs <- read.xls("input/AOCS_subtytpes.xlsx", as.is=TRUE)
clinical.aocs$X <- toupper(gsub(".cel$","", clinical.aocs$X))
esets.f$GSE9891_eset$aocs_subtype <-
    as.factor(clinical.aocs$k[match(sampleNames(esets.f$GSE9891_eset),
    clinical.aocs$X)])

tbl.aocs <- table( esets.f$GSE9891_eset$aocs_subtype, 
    apply(gsva.res$GSE9891_eset,2,which.max))
colnames(tbl.aocs) <- rownames(gsva.res[[1]])
@

\begin{figure}
<<subtypesosdiff,fig.width=10,fig.height=10,out.width="0.96\\textwidth",out.height="0.96\\textwidth">>=
par(mar=c(5,5,3,2), mfrow=c(2,2))
plotKM(y=dfrcboth$y, strata=dfrcboth$tcga_subtype,
censor.at=365.25*5,main="A)  All datasets except TCGA")
plotKM(y=esets.f$TCGA_eset$y, strata=esets.f$TCGA_eset$tcga_subtype,
censor.at=365.25*5,main="B)  TCGA")
plotKM(y=esets.f$GSE9891_eset$y, strata=esets.f$GSE9891_eset$aocs_subtype,
censor.at=365.25*5,main="C)  AOCS Subtypes in Tothill et al.")
@
\caption{Association of subtype and overall survival.  (A) All training and
validation datasets excluding TCGA. (B) Stratification of TCGA samples by
subtype. (C) Kaplan-Meier curves of the subtypes proposed by the Australian
Ovarian Cancer Study Group (AOCS) in Tothill et al \cite{Tothill:2008}. This
analysis corresponds to Figure 5B of the Tothill study, with the difference that here
we show only the late-stage, high-grade, serous tumors used in our
meta-analysis.}
\label{fig:km:subtypesos}
\end{figure}

We then tested for consistent overlaps with the Australian Ovarian Cancer
Study Group (AOCS) subtypes as published by Tothill et al.
\cite{Tothill:2008}. All mesenchymal samples were assigned to the AOCS cluster
c1, which had poor prognosis in the Tothill data (Supplemental
Figures~\ref{fig:km:subtypesos}C and \ref{fig:overlap:aocstcga}). Most
immunoreactive samples were assigned to the c2 cluster and c2 samples had
consistent with our results better outcome in the Tothill dataset.


\begin{figure}
<<subtypesaocsoverlap,fig.width=10,fig.height=10,out.width="0.96\\textwidth",out.height="0.96\\textwidth">>=
heatmap.2(tbl.aocs,col=topo.colors,trace="none",margin=c(12,5))
@
\caption{Comparison AOCS and TCGA subtypes in Tothill et al.
\cite{Tothill:2008}. Here we compare our classification of Tothill samples in
TCGA subtypes with the official Tothill et al. clusters. The colors as
indicated in the legend on the upper left corner visualize the number of
patients in the pairwise AOCS (rows) and TCGA (columns) subtype combinations.
For example, 35 patients of the AOCS cluster c1 were classified as
Mesenchymal.}
\label{fig:overlap:aocstcga}
\end{figure}


Verhaak et al.  proposed a multi-variate model
including tumor stage, debulking status, BRCA1/2 mutation status and ssGSEA
scores for the immunoreactive and mesenchymal subtypes.  BRCA1/2 mutation
status was unavailable for our validation datasets. As the survival
association of the ssGSEA scores were discovered in most of our validation
datasets, we tested a multivariate model using the CLOVAR patient
stratifications in high- and low-risk (based on the median of CLOVAR risk
scores in all datasets except the validation data), tumor stage, debulking
status and ssGSEA scores for all 4 subtypes. This model was then 5-fold
cross-validated using all datasets combined. This model performed very similar
to the one proposed by the authors using only 2 ssGSEA scores, but did not
require any biased feature selection.

\clearpage

% Prepare the debulking datasets (use only genes common to all platforms)
<<debulkingmetaprepare>>=
esets.debulking.f <- metaCMA.common.gene.esets(esets.debulking)
for (i in 1:length(esets.debulking.f)) esets.debulking.f[[i]]$debulking <- as.factor(esets.debulking.f[[i]]$debulking)
@

<<debulkingwithbonome,results='hide'>>=
X <- esets.debulking.f$GSE26712_eset
set.seed(1234)
s <- balancedstratification(X=cbind(1:ncol(X)),strata=paste(X$debulking,X$tumorstage),pik=rep(0.5,ncol(X)))
idx.bonometraining <- s==1
esets.debulking.f <- esets.debulking.f
esets.debulking.f$GSE26712_eset <- X[, idx.bonometraining]
Y <- X[, !idx.bonometraining]
write.csv(data.frame(GEO=sampleNames(Y), debulking=Y$debulking,
tumorstage=Y$tumorstage),file="output/bonomesamples_NOT_used_for_training.csv")
@

<<cached_medium_debulking_metas34b, cache=TRUE, results='hide'>>=
coefs.debulking.s34b <- metaCMA.coefs(esets.debulking.f, y="debulking", family=binomial)
res.debulking.s34b  <-
metaCMA(esets.debulking.f,y="debulking",coefs=coefs.debulking.s34b, n=200,
filter.fun=.debulkingFilter)
tmp <- metaCMA.opt(esets.debulking.f, coefs=coefs.debulking.s34b,n=200,y="debulking")
final.model.debulking <- tmp$model
@

\section{Comparison with the Berchuck 2004 debulking signature}

We generated a gene signature for suboptimal debulking surgery and validated
this signature by \textit{leave-one-dataset-out} cross-validation.  The
meta-analysis summary is shown in Supplemental
Figure~\ref{fig:roc:debulking} as ROC curves. In
Supplemental Table~\ref{ tbl:reg:debulking }, we show the logistic regression
coefficients of the gene signature risk score adjusted for FIGO stage (III vs.
IV). 

<<debulking_meta>>=
preds <- lapply(res.debulking.s34b$fits,function(fit) fit$risk@lp)
labels <- lapply(esets.debulking.f, function(X) X$debulking)
titles <- .getDatasetNames(esets.debulking.f)
idx.debfi <- !sapply(esets.debulking.f,.debulkingFilter)
@

\begin{figure}
<<cached_short_debulking_metaplot, cache=TRUE>>=
aucs.db <- .plotROCpanel(preds[idx.debfi],labels[idx.debfi],titles[idx.debfi],3,3)
@
\caption{Prediction of suboptimally debulked tumors in a leave-one-dataset-out
cross-validation. The prediction model calculates for each sample a score. The
higher the score, the higher the probability the tumor will be not optimally
debulkable. For each dataset, the model is trained using only the remaining
datasets. ROC curves visualize the true and false positive rates as a function of
the probability cutoffs.}  
\label{fig:roc:debulking}
\end{figure}

\begin{figure}
<<cached_short_debulking_berchuck04, cache=TRUE>>=
berchuck04 <- read.csv("input/berchuck04.csv",as.is=TRUE)
berchuck04.coefs <- berchuck04[,2]
names(berchuck04.coefs) <- berchuck04[,1]
# this uses a simple weighted average of the up minus the down regulated genes to calculate patient risk scores
model.berchuck04 <- new("linearriskscore", coefficients=berchuck04.coefs)
preds.berchuck04 <- lapply(esets.debulking.f, function(X) predict(model.berchuck04, newdata=X)@lp)
aucs.db.berchuck <-
.plotROCpanel(preds.berchuck04[idx.debfi][-7],labels[idx.debfi][-7],titles[idx.debfi][-7],3,3)
@
\caption{Prediction of debulking status with the Berchuck et al. signature
\cite{Berchuck:2004} as in Supplemental Figure~\ref{fig:roc:debulking}. The
Dressman data was excluded because a subset of Dressman samples was used for
training.}
\label{fig:roc:debulking:berchuck04}
\end{figure}

<<writemodelobjs>>=
save(final.model, final.model.debulking, file="output/models.rda")
@

<<cached_short_debulking_adjust,results='asis', cache=TRUE>>=
dfrc.debulking <- .createClinical(esets.debulking.f[idx.debfi])
dfrc.debulking$risk <- unlist(preds.berchuck04[idx.debfi])
dfrc.debulking$risk[grepl("Dressman",dfrc.debulking$batch)] <- NA

fit.debulking.berchuck04 <-
    glm(debulking~risk+tumorstage,dfrc.debulking,family="binomial")

dfrc.debulking$risk_berchuck04 <- dfrc.debulking$risk
dfrc.debulking$risk <- unlist(lapply(res.debulking.s34b$fits[idx.debfi], function(X)
X$risk@lp))

fit.debulking <-
    glm(debulking~risk+tumorstage,dfrc.debulking,family="binomial")
fit.debulking <-
    glm(debulking~risk+tumorstage,dfrc.debulking,family="binomial")

outreg(list(fit.debulking,fit.debulking.berchuck04), modelLabels=c("Meta-Analysis", "Berchuck et al. 2004"),
title="Prediction of debulking status. The table lists the
regression of our leave-one-dataset-out cross-validated meta-analysis
debulking gene signature
signature and the signature published by Berchuck et al. \\cite{Berchuck:2004}. The predictions were adjusted for tumor stage.",
label="tbl:reg:debulking", tight=FALSE,
varLabels=list(risk="Gene Signature",risk_berchuck04="Gene Signature",tumorstage="Stage (III vs IV)"))
@

<<cached_short_debulking_berchuck04_aucdiff,cache=TRUE>>=
aucdiff <- roc.test(roc(dfrc.debulking$debulking, dfrc.debulking$risk_berchuck04), roc(dfrc.debulking$debulking, dfrc.debulking$risk),alternative="less")
@

We compared our results to the only published model predicting debulking
success \cite{Berchuck:2004} we were aware of, with the corresponding ROC
curves shown in Supplemental Figure~\ref{fig:roc:debulking:berchuck04}.
Because Berchuck et al. did not provide the coefficients of their model, we
subtracted the average expression of genes down-regulated in suboptimal from
the average of up-regulated genes. The authors further did not specify the
exact probe sets and for only a subset of genes in their signature Unigene or
Genbank accession numbers. We manually tried to identify current HGNC symbols
for the genes. We could map 21 of the 32 genes utilized in their model to
probes used in curatedOvarianData.

<<qrtpcr, fig.width=3.5,include=FALSE>>=
qrtpcr <- read.xls("input/qrtpcr.xls", as.is=TRUE)
M <- t(as.matrix(qrtpcr[,9:16]))
colnames(M) <- qrtpcr[,3]

eset.qrtpcr <- ExpressionSet(impute.knn(M)$data,
    phenoData=phenoData(esets.debulking$GSE26712_eset[, colnames(M)]))
eset.qrtpcr.noimpute <- ExpressionSet(sqrt(M),
    phenoData=phenoData(esets.debulking$GSE26712_eset[, colnames(M)]))


eset.qrtpcr$grade <- qrtpcr$Grade

coefficients <- final.model.debulking@coefficients[featureNames(eset.qrtpcr)]

model.qrtpcr <- new("linearriskscore", coefficients=sign(coefficients),
modeltype="compoundcovariate")

.plotROCpanel(list( 
    predict(model.qrtpcr,newdata=esets.debulking$GSE26712_eset[,
        sampleNames(eset.qrtpcr)])@lp,
    predict(model.qrtpcr,newdata=eset.qrtpcr)@lp),
# should be the same
list(as.factor(esets.debulking$GSE26712_eset[,
sampleNames(eset.qrtpcr)]$debulking),
as.factor(eset.qrtpcr$debulking)), 
titles=c("Affymetrix", "qRT-PCR"), nrow=2, ncol=1)

@

<<cached_short_debulking_finalmodel_foldchanges, cache=TRUE>>=
load("input/eset.debulking.rda")
esets.db <- esets
esets.db <- esets.db[!sapply(esets.db, .debulkingFilter)]
esets.db <- .fixTCGA(esets.db)
# use only the half of Bonome used for training
ids <- sampleNames(esets.debulking.f$GSE26712_eset)[
    sampleNames(esets.debulking.f$GSE26712_eset) %in%
    sampleNames(esets.db$GSE26712_eset)]

esets.db$GSE26712_eset <- esets.db$GSE26712_eset[,ids]

.getFoldChanges <- function(esets.db, model) {
    res <- metaCMA.limma(lapply(esets.db, function(X)
        X[names(model@coefficients),]), "debulking",
        "suboptimal-optimal")
    resM <- do.call(cbind, lapply(res, function(r) topTable(r,number=200,
        sort.by="none")[,2]))
    resM <- cbind(resM, Weighted.Mean=apply(resM,1, weighted.mean, w=sqrt(sapply(
        esets.db, ncol))))
    rownames(resM) <- names(model@coefficients)
    resM[,1:9] <- 2^resM[,1:9]
    resM[,1:9] <- apply(resM[,1:9],c(1,2),function(x) ifelse(x<1, 1/(x*-1),x))
    resM    
}

resM <- .getFoldChanges(esets.db, final.model.debulking)

@

<<cached_short_debulking_finalmodel,cache=TRUE>>=
# Write the final debulking model to a spreadsheet.
sig <- names(final.model.debulking@coefficients)

probesets <- do.call(cbind, lapply(esets.debulking.f, function(X)
 as.character(featureData(X)[sig,]$maxmean_probeset)))

tmp <- data.frame(Genes=sig, probesets, 
"Pooled LogIt Coefficient"=
final.model.debulking@coefficients,
"Mean Optimal"= apply(tmp$train$X[which(tmp$train$y=="optimal"),],2,mean),
"Mean Suboptimal"= apply(tmp$train$X[which(tmp$train$y=="suboptimal"),],2,mean),
 P=head(sort(tmp$pvalues),length(sig)),
 FDR=head(sort(p.adjust(tmp$pvalues,method="BH")),length(sig)), resM)

write.csv(tmp[order(abs(tmp$Weighted.Mean), decreasing=TRUE),],
 file="output/final_signature_debulking.csv",row.names=FALSE)
@

\clearpage
\bibliographystyle{plain}
\bibliography{metasig}
\newpage
\clearpage
\appendix

<<cached_medium_datasetshr2prepare, cache=TRUE>>=
.allCombsEval <- function(ids, esets, object) {
       lodo <- .lodocvPlot(esets, models=object$fits[[1]]$fit, ids=ids,
       plot=FALSE)[[1]]
       fit <- coxph(lodo$y~lodo$strata)
       summary(fit)$coefficients
}
esets.fx <- c(esets.f, GSE32062.GPL6480_eset=esets.validation$GSE32062.GPL6480_eset)
esets.fx <- metaCMA.common.gene.esets(esets.fx)
coefs.fx <- metaCMA.coefs(esets.fx)
@

<<cached_long_datasetshr2, cache=TRUE>>=
ret.hr <- lapply(1:length(esets.fx), metaCMA.allcombinations, esets=esets.fx,
    coefs=coefs.fx, n=200,eval.fun=.allCombsEval )
@

<<plotdatasetshrprepare>>=
.filterfx <- function(eset) { 
    ncol(eset)==129 | ncol(eset) < 75 
}

df.hr <- do.call(rbind, lapply(1:length(esets.fx),
function(i) data.frame(.getDatasetNames(esets.fx)[i], unlist(ret.hr[[i]]$n),
  sapply(ret.hr[[i]]$evaluation, function(y) 1/y[2]))))
 
colnames(df.hr) <-c("Dataset", "n", "HR")

.psContains <- function(i, esets, s) {
    .doPS <- function(ps) {
        idx <- (1:length(esets))[-i][ps]
        ifelse(sum(grepl(s, names(esets)[idx]))>0, "Yes", "No")
     }
     pss <- metaCMA.powerset(length(esets[-i]))
     ret <- lapply(pss, .doPS)
}
df.hr$containstcga <- unlist(lapply(1:length(esets.fx), .psContains, esets.fx,"TCGA"))

filtered <- names(esets.fx)[which(sapply(esets.fx, .filterfx))]
.psContains <- function(i, esets) {

    .doPS <- function(ps) {
        idx <- (1:length(esets))[-i][ps]
        ifelse(sum(filtered %in% names(esets)[idx])>0, "No", "Yes")
     }
     pss <- metaCMA.powerset(length(esets[-i]))
     ret <- lapply(pss, .doPS)
}

df.hr$meta <- unlist(lapply(1:length(esets.fx), .psContains, esets.fx))


#df.hr <- df.hr[df.hr$meta=="Yes",]

p <-ggplot(df.hr, aes(n,HR))
#p <- p +geom_point(aes(col=meta,shape=meta),size=1.3)
p <- p +geom_point(size=0.75)
p <- p +facet_wrap(~Dataset)+coord_cartesian(ylim= c(0.75, 2.9))+ylab("Hazard Ratio")+xlab("Total Training Sample Size")
#p <- p+ scale_shape(solid=FALSE, name = "Training Dataset")
#p <- p+ scale_colour_discrete( name = "Training Dataset")
p <-p +geom_smooth(method="lm")
p <- p +theme(axis.text.x=element_text(angle=45,hjust=1))
@

<<plotdatasetshr, include=FALSE>>=
facetAdjust(p+theme_classic(14)+theme(axis.text.x = element_text(angle = 45, hjust = 1)))
@

<<comptcga,fig.width=5.33,fig.height=8,out.width="0.467\\textwidth",out.height="0.7\\textwidth",results='hide',include=FALSE>>=

fit.clinical <- coxph(y~tumorstage+debulking_orig,dfrcboth)

fit <- coxph(y~strata+tumorstage+debulking_orig,dfrcboth)
fit.jci <-
coxph(y~strata_jci+tumorstage+debulking_orig+Immunoreactive+Mesenchymal+Proliferative+Differentiated,dfrcboth)

yhat <- cvRisk(fit, dfrcboth)
yhat.jci <- cvRisk(fit.jci, dfrcboth)
yhat.clinical <- cvRisk(fit.clinical, dfrcboth)

par(mfrow=c(3,2))
par(mar=c(4.5, 4.1, 2.5, 1.5))
plotKM(y=dfrcboth$y, strata=dfrcboth$strata,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="A)   Meta-Analysis Signature")
plotKMStratifyBy("median",y=dfrcboth$y,linearriskscore=yhat,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="B)  Signature + Stage + Debulking")
plotKMStratifyBy("median",y=dfrcboth$y,linearriskscore=yhat.clinical,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="C)  Stage and Debulking only")
plotKM(y=dfrcboth$y, strata=dfrcboth$strata_tcga,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="D)   TCGA Signature")
plotKM(y=dfrcboth$y, strata=dfrcboth$strata_jci,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="E)   Verhaak et al. Signature")
plotKMStratifyBy("median", y=dfrcboth$y, linearriskscore=yhat.jci,
        censor.at=365.25*5,
        show.n.risk=FALSE,show.legend=FALSE,show.HR=TRUE,cex.HR=1.1,
        show.PV=FALSE,
        xlab="Time (Days)",
        cex.base=1.4,main="F)   Verhaak et al. Multivariate")

@

<<fpcomptcga,fig.width=7.75,fig.height=11.5,out.width="0.4\\textwidth",out.height="0.7\\textwidth",results='hide',include=FALSE>>=
Xs.all <- c(esets.f[-8], esets.validation[-4])
names(Xs.all) <- .getDatasetNames(Xs.all)

res.strata <- lapply(c(res.lodo, res.val[-4]), function(x) x$strata)
res.strata.tcga <- lapply(c(res.lodo.tcga, res.val.tcga[-4]), function(x) x$strata)
res.strata.jci <- lapply(c(res.lodo.jci, res.val.jci[-4]), function(x) x$strata)

x <- metaCMA.forest.models(metaCMA.censor(Xs.all,censor.at=365.25*5),
risks=list(res.strata, res.strata.tcga, res.strata.jci),
 graphwidth=unit(2.5,
 "inches"),concordance=FALSE,inverse=TRUE,x.ticks=c(0.5,1,2,4,8),clip=log(c(0.5,8)),
 cols=c("darkblue","seagreen", "red"))
@

<<cached_medium_hrdiffconfint, cache=TRUE>>=
d.f <- data.frame( do.call(rbind,lapply(metaCMA.censor(Xs.all,censor.at=365.25*5), function(X) X$y)),
strata=dfrcboth$strata, strata_tcga=dfrcboth$strata_tcga)

hrdiffemp <- .boostrapHRs(d.f,n=10000,inverse=TRUE)
hrdiffci <- quantile(hrdiffemp,c(0.025,0.975))
@

<<cached_medium_hrdiffconfintjci, cache=TRUE>>=
d.f <- data.frame( do.call(rbind,lapply(metaCMA.censor(Xs.all,censor.at=365.25*5), function(X) X$y)),
strata=dfrcboth$strata_jci, strata_tcga=dfrcboth$strata_tcga)

hrdiffjciemp <- .boostrapHRs(d.f,n=10000,inverse=TRUE)
hrdiffjcici <- quantile(hrdiffjciemp,c(0.025,0.975))
@

\clearpage
\section{Session Info}
<<sessioninfo, results='asis', echo=FALSE>>=
toLatex(sessionInfo())
@

\end{document}
